{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### 10 Emoji Prediction\n",
    "\n",
    "The task of this project is to make a system that would automatically fill the text with the appropriate emoticons. This can be done in two steps. First, for each position within the text a prediction is made whether an emoticon should be placed there. Second, an appropriate emoticon is chosen from a list of available emoticons. Both these tasks can be set up as supervised classification problems.\n",
    "\n",
    "Competition website:\n",
    "https://competitions.codalab.org/competitions/17344\n",
    "\n",
    "Dataset:\n",
    "https://competitions.codalab.org/competitions/17344\n",
    "\n",
    "Entry point:\n",
    "https://arxiv.org/pdf/1702.07285.pdf (Barbieri, Francesco, Miguel Ballesteros, and Horacio Saggion. Are Emojis Predictable?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Define paths to folders containing the data and the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_TWEETS = \"ALL\"\n",
    "# NUMBER_OF_TWEETS = 100000\n",
    "\n",
    "MAX_WORDS_PER_TWEET = 30\n",
    "# DATA_LOCATION = \"./train/data/noise/\"\n",
    "DATA_LOCATION = \"./train/data/clean/\"\n",
    "# DATA_LOCATION = \"./train/data/words/\"\n",
    "RESULT_LOCATION = \"./result/\"\n",
    "TWEET_FILE_NAME = \"tweet_by_ID_28_4_2018__03_20_05\" + \"_\"\n",
    "\n",
    "k = 3\n",
    "\n",
    "if NUMBER_OF_TWEETS is not None:\n",
    "    TWEET_FILE_NAME += str(NUMBER_OF_TWEETS)\n",
    "else:\n",
    "    TWEET_FILE_NAME += \"ALL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Load the data\n",
    "Tweets are loaded in two ways: list of strings (for the TF-IDF vectorizer) and a list of lists of words (for feature extraction). Labels are read as a numpy array of N * MAX_WORDS_PER_TWEET dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tweets 473459\n",
      "example of tweet texts:\n",
      "lol @ west covina , california\n",
      "things got a little festive at the office @ redrock\n",
      "step out and explore . @ ellis island cafe\n",
      "@user @ cathedral preparatory school\n",
      "my baby bear @ bubby's\n",
      "rupaul's drag race bingo fun . drag queens be sexy ! @user abwyman\n",
      "black history like a mufffffaaaaaka done thru her yugioh trap card like hell\n",
      "just light makeup\n",
      "@ bj's restaurant and brewhouse\n",
      "so lovely catching up with my soul sister @user @ university of victoria\n",
      "\n",
      "example of labels (emoji locations):\n",
      "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "example of labels (emoji type):\n",
      "[[ 0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "base_file_name = DATA_LOCATION + TWEET_FILE_NAME\n",
    "\n",
    "text_lines = []\n",
    "text_lines_split = []\n",
    "\n",
    "with open(base_file_name + \".text\", 'r', encoding=\"utf-8\") as out_text:\n",
    "    for line in out_text:\n",
    "        text_lines.append(line[:-1])\n",
    "        text_lines_split.append(line[:-1].split())\n",
    "        \n",
    "loc_lines = []\n",
    "with open(base_file_name + \".loclabels\", 'r') as loc_labels:\n",
    "    for line in loc_labels:\n",
    "        loc_line = []\n",
    "        for c in line[:-1]:\n",
    "            loc_line.append(int(c))\n",
    "        loc_lines.append(loc_line)\n",
    "\n",
    "loc_lines = np.asarray(loc_lines)\n",
    "\n",
    "emo_lines = []\n",
    "with open(base_file_name + \".emolabels\", 'r') as emo_labels:\n",
    "    for e_line, loc in zip(emo_labels, loc_lines):\n",
    "        emo_line = [0]*31\n",
    "        e_line2 = e_line.split()\n",
    "        \n",
    "        br = 0\n",
    "        for idx, val in enumerate(loc[:-1]):\n",
    "            if val==1:\n",
    "                emo_line[idx]=int(e_line2[br])+1\n",
    "                br += 1\n",
    "        emo_lines.append(emo_line)\n",
    "        \n",
    "emo_lines = np.asarray(emo_lines)\n",
    "\n",
    "print(f\"number of tweets {len(text_lines)}\")\n",
    "print(f\"example of tweet texts:\")\n",
    "for i in range(10):\n",
    "    print(f\"{text_lines[i]}\")\n",
    "print(f\"\\nexample of labels (emoji locations):\\n{loc_lines[:10]}\")\n",
    "print(f\"\\nexample of labels (emoji type):\\n{emo_lines[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### TF-IDF Feature Extraction\n",
    "TF-IDF is computed on the collection of tweets. Then for every position between words a new example is generated: a $2*k$ array containing the k left and k right tf-idf values of words. Labels are taken as 1 or 0 wether an emoji was there in the original tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import random\n",
    "\n",
    "X_tfidf = None\n",
    "word_to_tfidf_index_dict = {}\n",
    "\n",
    "def tfidf_features(tweets, loc_labels, emo_labels, k, func):\n",
    "    global word_to_tfidf_index_dict, X_tfidf\n",
    "    \n",
    "    tfidf_model = TfidfVectorizer(input=\"content\", analyzer=\"word\", stop_words=\"english\")\n",
    "    X_tfidf = tfidf_model.fit_transform(text_lines)\n",
    "\n",
    "    #word_to_tfidf_index_dict = {}\n",
    "    for i, word in enumerate(tfidf_model.get_feature_names()):\n",
    "        word_to_tfidf_index_dict[word] = i\n",
    "\n",
    "    print(f\"X shape {X_tfidf.shape}\")\n",
    "    print(f\"y_l shape {loc_lines.shape}\")\n",
    "    print(f\"y_e shape {emo_lines.shape}\")\n",
    "    print(f\"some tf-idf values\\n{X_tfidf[0]}\\n\")\n",
    "\n",
    "    N = len(tweets)\n",
    "    X = []\n",
    "    y_l = []\n",
    "    y_e = []\n",
    "    \n",
    "    for tweet_index, (tweet, l_label, e_label) in enumerate(zip(tweets, loc_labels, emo_labels)):\n",
    "        for pos in range(len(tweet) + 1):\n",
    "                \n",
    "            x = []\n",
    "            for i in range(pos - k, pos + k):\n",
    "                if i < 0 or i >= len(tweet):\n",
    "                    x.append(0.0)\n",
    "                else:\n",
    "                    x.append(func(tweet_index, tweet[i]))\n",
    "            X.append(x)\n",
    "            y_l.append(l_label[pos])\n",
    "            y_e.append(e_label[pos])\n",
    "            \n",
    "    return np.asarray(X), np.asarray(y_l), np.asarray(y_e)\n",
    "\n",
    "def word_to_tfidf(tweet_index, word):\n",
    "    global word_to_tfidf_index_dict, X_tfidf\n",
    "    \n",
    "    if word in word_to_tfidf_index_dict:\n",
    "        return X_tfidf[tweet_index, word_to_tfidf_index_dict[word]]\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def print_dataset(X, y_l, y_e):\n",
    "    emoji_num = np.count_nonzero(y_l)\n",
    "    class_freq_ratio = emoji_num / (X.shape[0] * X.shape[1])\n",
    "    \n",
    "    print(\"after feature extraction:\")\n",
    "    print(f\"X shape {X.shape}\")\n",
    "    print(f\"y_l shape {y_l.shape}\")\n",
    "    print(f\"y_e shape {y_e.shape}\")\n",
    "    print(f\"some X values\\n{X[:5]}\")\n",
    "    print(f\"some y_l values\\n{y_l[:5]}\")\n",
    "    print(f\"non zero elements (1 in label) in y_l {emoji_num}\")\n",
    "    print(f\"class frequency ratio {class_freq_ratio}\\n\")\n",
    "    print(f\"some y_e values\\n{y_e[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vector Feature Extraction\n",
    "\n",
    "A similar dataset is obtained using w2vec. By setting the number of features to $2*k=6$, the dimensionality stays the same as the previous tf-idf feature extraction. For each word a 6 dimensional vector is obtained and then the average of the 6 neighboring words is taken. Labels stay the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "num_of_features = 2 * k\n",
    "w2v_model_file_name = \"w2v_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(text_lines_split, min_count=1, size=num_of_features)\n",
    "w2v_model.save(w2v_model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load(w2v_model_file_name)\n",
    "\n",
    "example = w2v_model.wv[\"california\"]\n",
    "print(example.shape)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_features(tweets, labels, k):\n",
    "    N = len(tweets)\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for tweet_index, (tweet, label) in enumerate(zip(tweets, labels)):\n",
    "        for pos in range(len(tweet) + 1):\n",
    "            x = []\n",
    "            for i in range(pos - k, pos + k):\n",
    "                if i < 0 or i >= len(tweet):\n",
    "                    x.append(np.zeros(num_of_features))\n",
    "                else:\n",
    "                    x.append(w2v_model.wv[tweet[i]])\n",
    "            x = np.average(x, axis=0)\n",
    "            X.append(x)\n",
    "            y.append(label[pos])\n",
    "            \n",
    "    return np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# should_use_tfidf = True\n",
    "# should_use_hybrid = False\n",
    "\n",
    "# X_tfidf, y_tfidf = tfidf_features(text_lines_split, loc_lines, k, word_to_tfidf)\n",
    "# X_w2v, y_w2v = w2v_features(text_lines_split, loc_lines, k)\n",
    "# X_hybrid = np.hstack((X_tfidf, X_w2v))\n",
    "\n",
    "# if should_use_tfidf or should_use_hybrid:    \n",
    "#     X, y = X_tfidf, y_tfidf\n",
    "\n",
    "# if (not should_use_tfidf) or should_use_hybrid:\n",
    "#     X, y = X_w2v, y_w2v\n",
    "\n",
    "# if should_use_hybrid:\n",
    "#     X = X_hybrid\n",
    "\n",
    "# print_dataset(X, y)\n",
    "\n",
    "X_tfidf, y_loc_tfidf, y_emo_tfidf = tfidf_features(text_lines_split, loc_lines, emo_lines, k, word_to_tfidf)\n",
    "\n",
    "X_train, X_test, y_loc_train, y_loc_test = train_test_split(X_tfidf, y_loc_tfidf, shuffle=False, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Baselines\n",
    "\n",
    "Make sure to check should_train flags when training/testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "should_use_kfold = True\n",
    "\n",
    "should_train_global = True\n",
    "should_train_linear_svm = True\n",
    "should_train_bagging_svm = False\n",
    "should_train_random_forest = False\n",
    "should_train_adaboost = True\n",
    "\n",
    "linear_svm_model_file_name = \"linear_svm.pkl\"\n",
    "bagging_model_file_name = \"bagging_svm.pkl\"\n",
    "random_forest_file_name = \"random_forest.pkl\"\n",
    "adaboost_file_name = \"adaboost.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "EVALUATION_RESULTS_KEYS = ['Accuracy: ', 'Precision: ', 'Recall: ', 'F1: ', 'ratio of positive/negative predictions: ']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "def vectorize_func(a, b):\n",
    "    if a == b:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def calc_scores(y_pred, y_test, multi_class):\n",
    "    result = []\n",
    "    \n",
    "    if multi_class:\n",
    "        result_temp = []\n",
    "    \n",
    "        for i in range(0, 21):\n",
    "            vfunc = np.vectorize(vectorize_func)\n",
    "            y_test_new = vfunc(y_test, i)\n",
    "            y_pred_new = vfunc(y_pred, i)\n",
    "            \n",
    "            result_temp2 = []\n",
    "            alfa=1\n",
    "            if i == 0:\n",
    "                alfa=1/5\n",
    "            \n",
    "            result_temp2.append(alfa*accuracy_score(y_pred_new, y_test_new))\n",
    "            result_temp2.append(alfa*precision_score(y_pred_new, y_test_new))\n",
    "            result_temp2.append(alfa*recall_score(y_pred_new, y_test_new))\n",
    "            result_temp2.append(alfa*f1_score(y_pred_new, y_test_new))\n",
    "            result_temp.append(result_temp2)\n",
    "    \n",
    "        result_avg = np.average(np.asarray(result_temp), axis=0)\n",
    "        result = result_avg[:]\n",
    "    else:\n",
    "        result.append(accuracy_score(y_pred, y_test))\n",
    "        result.append(precision_score(y_pred, y_test))\n",
    "        result.append(recall_score(y_pred, y_test))\n",
    "        result.append(f1_score(y_pred, y_test))\n",
    "        result.append(np.count_nonzero(y_pred) / y_pred.shape[0])\n",
    "    return result\n",
    "\n",
    "def print_scores(scores):\n",
    "    print(f\"Accuracy: {scores[0]}\")\n",
    "    print(f\"Precision: {scores[1]}\")\n",
    "    print(f\"Recall: {scores[2]}\")\n",
    "    print(f\"F1: {scores[3]}\")\n",
    "    if len(scores) > 4:\n",
    "        print(f\"ratio of positive/negative predictions {scores[4]}\")\n",
    "\n",
    "def kfold_score(clf, X, y):\n",
    "    fold_scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_kf, X_test_kf = X[train_index], X[test_index]\n",
    "        y_train_kf, y_test_kf = y[train_index], y[test_index]\n",
    "        clf.fit(X_train_kf, y_train_kf)\n",
    "        y_pred = clf.predict(X_test_kf)\n",
    "        fold_scores.append(calc_scores(y_pred, y_test_kf))\n",
    "    \n",
    "    fold_scores = np.average(np.asarray(fold_scores), axis=0)\n",
    "    print_scores(fold_scores)\n",
    "\n",
    "def train_and_save_model(model, X_train, y_train, model_file_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    joblib.dump(model, model_file_name)\n",
    "    \n",
    "def load_and_test_model(model_file_name, X_test, y_test):\n",
    "    clf_loaded = joblib.load(model_file_name)\n",
    "    y_pred = clf_loaded.predict(X_test)\n",
    "    print_scores(calc_scores(y_pred, y_test))\n",
    "    \n",
    "def do_test(clf, X, y, clf_file_name, flag):\n",
    "    if should_use_kfold:\n",
    "        kfold_score(clf, X, y)\n",
    "    else:\n",
    "        if should_train_global and flag:\n",
    "            train_and_save_model(clf, X_train, y_train, clf_file_name)\n",
    "        load_and_test_model(clf_file_name, X_test, y_test)\n",
    "        \n",
    "def write_to_file(best_params, results, baseline_name, loc_or_emo):\n",
    "    timestr = time.strftime(\"%d_%m_%Y__%H_%M_%S_\")\n",
    "    FOLDER_LOCATION = RESULT_LOCATION + \"baselines/\" + baseline_name + \"/\"\n",
    "    FILE_NAME = baseline_name + \"_\" + loc_or_emo + \"_\" + timestr\n",
    "    if NUMBER_OF_TWEETS is not None:\n",
    "        FILE_NAME += str(NUMBER_OF_TWEETS)\n",
    "    else:\n",
    "        FILE_NAME += \"ALL\"\n",
    "    FILE_NAME += '.text'\n",
    "    RESULTS_FILE_NAME = FOLDER_LOCATION + FILE_NAME\n",
    "\n",
    "    file = open(RESULTS_FILE_NAME, \"w+\")\n",
    "    file.write(baseline_name + \", \" + loc_or_emo + \":\\n\\n\")\n",
    "    for key, val in best_params.items():\n",
    "        file.write(key+ \": \"+str(val)+\"\\n\")\n",
    "    file.write(\"\\n\")\n",
    "    for i, res in enumerate(results):\n",
    "        file.write(EVALUATION_RESULTS_KEYS[i]+str(res)+\"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "dummy_clf.fit(X_train, y_loc_train)\n",
    "dummy_pred = dummy_clf.predict(X_test)\n",
    "print(calc_scores(y_loc_test, dummy_pred, multi_class=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Linear SVM Baseline\n",
    "\n",
    "Linear SVM is based on the liblinear library and is faster on large datasets. Not using dual optimization problem makes the training extremely fast (pseudoinverse). It is the fastest so both feature extraction methods (TF-IDF and word2vec) are used for comparison. TF-IDF works better, but adding word2vec to it (hybrid approach) adds a little bit of improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "#svm_clf = LinearSVC(class_weight=\"balanced\", dual=False)\n",
    "X_train, X_test, y_loc_train, y_loc_test = train_test_split(X_tfidf, y_loc_tfidf, shuffle=False, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "# Parameter tunning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "parameters = {'C':[0.05, 0.5, 1, 2]}\n",
    "scoring = 'f1'\n",
    "clf = GridSearchCV(svm_clf, parameters, cv=5, scoring=scoring)\n",
    "clf.fit(X_tfidf, y_loc_tfidf)\n",
    "\n",
    "best_estimator = clf.best_estimator_\n",
    "best_params = {}\n",
    "best_params['C'] = clf.best_params_['C']\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "X_train2, X_val, y_loc_train2, y_loc_val = train_test_split(X_train, y_loc_train, test_size=0.2, random_state=42)\n",
    "c_range = (-5, 15)\n",
    "param_C = [2**i for i in range(c_range[0], c_range[1]+1)]\n",
    "\n",
    "c_size = c_range[1]-c_range[0]+1\n",
    "results_test = np.zeros(c_size, dtype = np.float64)\n",
    "for i in range(c_size):\n",
    "    C1 = param_C[i]\n",
    "            \n",
    "    svm_clf = LinearSVC(class_weight=\"balanced\", dual=False, C=C1)\n",
    "    results = kfold_score(svm_clf, X_train, y_loc_train, multi_class=False, print1=False)\n",
    "    results_test[i] = results[3]\n",
    "    \n",
    "    #svm_clf.fit(X_train2, y_loc_train2)\n",
    "\n",
    "    #results_test[i] = zero_one_loss(y_loc_val, svm_clf.predict(X_val))\n",
    "    #results_test[i] = f1_score(y_loc_val, svm_clf.predict(X_val), average='binary') \n",
    "print(results_test)\n",
    "Ci = results_test.argmax()\n",
    "C_best = param_C[Ci]\n",
    "\n",
    "best_params = {}\n",
    "best_params['C'] = C_best\n",
    "\n",
    "best_estimator = LinearSVC(class_weight=\"balanced\", dual=False, C=C_best)\n",
    "best_estimator.fit(X_train, y_loc_train)\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "for key, val in best_params.items():\n",
    "    print(key+ \": \"+str(val))\n",
    "print(classification_report(y_loc_test, y_pred))\n",
    "\n",
    "\n",
    "# K-fold \n",
    "\n",
    "print(\"Emoji locations:\\n\")\n",
    "print(\"TF-IDF results:\")\n",
    "results = do_test(best_estimator, X_tfidf, y_loc_tfidf, linear_svm_model_file_name, should_train_linear_svm)\n",
    "\n",
    "# Writing results into a file\n",
    "write_to_file(best_params, results, \"linearSVM\", \"locations\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Training and testing the best estimator\n",
    "\n",
    "svm_clf = LinearSVC(class_weight=\"balanced\", dual=False, C=0.05)\n",
    "svm_clf.fit(X_train, y_loc_train)\n",
    "y_loc_pred_svm = svm_clf.predict(X_test)\n",
    "fold_scores = calc_scores(y_loc_pred_svm, y_loc_test, False)\n",
    "print_scores(fold_scores, False)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "svm_clf = LinearSVC(class_weight=\"balanced\", dual=False)\n",
    "X_train, X_test, y_emo_train, y_emo_test = train_test_split(X_tfidf, y_emo_tfidf, shuffle=False, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Parameter tunning\n",
    "\n",
    "parameters = {'C':[0.05, 0.5, 1, 2]}\n",
    "scoring = 'f1_micro'\n",
    "clf = GridSearchCV(svm_clf, parameters, cv=5, scoring=scoring)\n",
    "clf.fit(X_tfidf, y_emo_tfidf)\n",
    "\n",
    "best_estimator = clf.best_estimator_\n",
    "best_params = {}\n",
    "best_params['C'] = clf.best_params_['C']\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "for key, val in best_params.items():\n",
    "    print(key+ \": \"+str(val))\n",
    "print(classification_report(y_emo_test, y_pred))\n",
    "\n",
    "\n",
    "# K-fold \n",
    "\n",
    "print(\"Emoji types:\\n\")\n",
    "print(\"TF-IDF results:\")\n",
    "results = do_test(best_estimator, X_tfidf, y_emo_tfidf, linear_svm_model_file_name, should_train_linear_svm, True)\n",
    "\n",
    "# Writing results into a file\n",
    "write_to_file(best_params, results, \"linearSVM\", \"emojis\")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Training and testing the best estimator\n",
    "\n",
    "svm_clf = LinearSVC(class_weight=\"balanced\", dual=False, C=0.05)\n",
    "svm_clf.fit(X_train, y_emo_train)\n",
    "y_emo_pred_svm = svm_clf.predict(X_test)\n",
    "fold_scores = calc_scores(y_emo_pred_svm, y_emo_test, True)\n",
    "print_scores(fold_scores, True)\n",
    "\n",
    "#print(y_emo_pred_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Bagging SVM\n",
    "\n",
    "Warning! SVM is based on the libsvm library and it scales poorly with large datasets. That is why an ensemble (bagging) is used. Each classifier is trained on a portion of the data which greatly reduces training times and gives similar (if not better) results. Using 10 estimators it still takes a few hours to train. Results are just a bit better than a single linear SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "n_estimators = 10\n",
    "bagging_svm_clf = BaggingClassifier(SVC(kernel='linear', class_weight='balanced'), max_samples=1.0 / n_estimators,\n",
    "                                        n_estimators=n_estimators, bootstrap=False)\n",
    "\n",
    "do_test(bagging_svm_clf, X, y, bagging_model_file_name, should_train_bagging_svm)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Random Forest Baseline\n",
    "\n",
    "Random forests are pretty fast and are generally better than the SVM. Higher accuracy and recall, but worse precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest_clf = RandomForestClassifier(min_samples_leaf=2, class_weight=\"balanced\")\n",
    "\n",
    "do_test(random_forest_clf, X, y, random_forest_file_name, should_train_random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### AdaBoost Baseline\n",
    "\n",
    "AdaBoost gives the best results and is relatively fast to train. It is slower than random forests, but still faster than bagging svms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "adaboost_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2, class_weight=\"balanced\"), n_estimators=100)\n",
    "\n",
    "do_test(adaboost_clf, X, y, adaboost_file_name, should_train_adaboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLSTM for emoji location prediction\n",
    "\n",
    "Bidirectional long short-term memory recurrent network implementation using the Keras framework. Emoji location prediction is treated as a binary classification problem. TWEET_NUM determines how much of the tweets are used for training. The model uses an embedding layer and its size is a hyperparameter. Using pretrained Glove embeddings proved to be better. A single bidirectional layer is used which actually consists of two LSTM layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "GLOVE_DIR = \"./embeddings/\"\n",
    "GLOVE_FILE_NAME = \"glove.twitter.27B.\"\n",
    "GLOVE_FILE_NAME_EXT = \"d.txt\"\n",
    "\n",
    "MODEL_DIR = \"./blstm_models/\"\n",
    "BLSTM_BASE_FILE_NAME = \"blstm_model_\"\n",
    "BLSTM_FILE_NAME_EXT = \".h5\"\n",
    "\n",
    "N_TIMESTEPS = MAX_WORDS_PER_TWEET + 1\n",
    "NUM_EMOJI_TYPES = 20\n",
    "TEST_SPLIT_SIZE = 0.2\n",
    "VALIDATION_SPLIT = 0.1\n",
    "EARLY_STOPPING_PATIENCE = 2\n",
    "MAX_EPOCH = 30\n",
    "\n",
    "TWEET_NUM = len(text_lines)\n",
    "# TWEET_NUM = 100000\n",
    "INPUT_SIZE = int(TWEET_NUM * (1 - TEST_SPLIT_SIZE))\n",
    "NUM_OF_VOCAB = None\n",
    "EMBEDDING_SIZE = 200\n",
    "HIDDEN_SIZE = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "Words are converted to integer ids using a tokenizer. Each unique word has its own unique integer value. Tweets are padded with zeros to a set length. Padding is required by Keras. Since most of the labels are zero (emojis are present after every 15th word), class weights are calculated. Without class weights the model behaves like a majority class classifier which is of no use here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 137097\n",
      "input shape: (378767, 31)\n",
      "BLSTM input example:\n",
      "[[    0   148   206  5683    66     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0   289    58     6    62  2312    15     1   642 21191     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0  1463    36     7  3494  5219   205   353     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0     2  2278  7381    79     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0     3   129   944 15100     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]]\n",
      "\n",
      "location labels shape: (378767, 31, 2)\n",
      "\n",
      "BLSTM loc labels:\n",
      "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "emo labels shape: (378767, 31, 21)\n",
      "\n",
      "BLSTM emo labels:\n",
      "[[ 0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]]\n",
      "\n",
      "sample_weights_loc shape: (378767, 31)\n",
      "sample_weights_loc examples:\n",
      "[[ 0.51698246 15.22107008  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246]\n",
      " [ 0.51698246  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246  0.51698246 15.22107008  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246]\n",
      " [ 0.51698246  0.51698246  0.51698246  0.51698246  0.51698246 15.22107008\n",
      "   0.51698246  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246]\n",
      " [15.22107008  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246]\n",
      " [ 0.51698246  0.51698246  0.51698246 15.22107008  0.51698246  0.51698246\n",
      "   0.51698246  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246  0.51698246  0.51698246  0.51698246  0.51698246  0.51698246\n",
      "   0.51698246]]\n",
      "\n",
      "sample_weights_emo shape: (378767, 31)\n",
      "sample_weights_emo examples:\n",
      "[[4.92361517e-02 1.42490377e+01 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02]\n",
      " [4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  5.48383913e+01 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02]\n",
      " [4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 6.70317862e+00 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02]\n",
      " [5.45228901e+01 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02]\n",
      " [4.92361517e-02 4.92361517e-02 4.92361517e-02 1.40007071e+01\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02 4.92361517e-02\n",
      "  4.92361517e-02 4.92361517e-02 4.92361517e-02]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_input = text_lines[:TWEET_NUM]\n",
    "y_input = loc_lines[:TWEET_NUM]\n",
    "y_emo_input = emo_lines[:TWEET_NUM]\n",
    "\n",
    "abc = 100000\n",
    "\n",
    "# X_blstm_train, y_blstm_train, y_blstm_emo_train = X_input[:abc], y_input[:abc], y_emo_input[:abc]\n",
    "X_blstm_train, y_blstm_train, y_blstm_emo_train = X_input[:INPUT_SIZE], y_input[:INPUT_SIZE], y_emo_input[:INPUT_SIZE]\n",
    "X_blstm_test, y_blstm_test, y_blstm_emo_test = X_input[INPUT_SIZE:], y_input[INPUT_SIZE:], y_emo_input[INPUT_SIZE:]\n",
    "\n",
    "# X_blstm_train, X_blstm_test, y_blstm_train, y_blstm_test = train_test_split(X_input, y_input, test_size=TEST_SPLIT_SIZE)\n",
    "\n",
    "if NUM_OF_VOCAB is not None:\n",
    "    tokenizer = Tokenizer(num_words=NUM_OF_VOCAB)\n",
    "else:\n",
    "    tokenizer = Tokenizer()\n",
    "    \n",
    "tokenizer.fit_on_texts(X_input)\n",
    "word_index = tokenizer.word_index\n",
    "txt_to_seq = tokenizer.texts_to_sequences(X_blstm_train)\n",
    "# print(f\"encoded:\\n{txt_to_seq[0:5]}\\n\")\n",
    "\n",
    "if NUM_OF_VOCAB is not None:\n",
    "    vocab_size = NUM_OF_VOCAB + 1\n",
    "else:\n",
    "    vocab_size = len(word_index) + 1\n",
    "\n",
    "print(f\"Vocabulary Size: {vocab_size}\")\n",
    "\n",
    "X_blstm = pad_sequences(txt_to_seq, maxlen=N_TIMESTEPS - 1, padding='post')\n",
    "start_padding = np.zeros((X_blstm.shape[0], 1))\n",
    "X_blstm = np.append(start_padding, X_blstm, axis=1).astype(int)\n",
    "print(f\"input shape: {X_blstm.shape}\")\n",
    "print(f\"BLSTM input example:\\n{X_blstm[:5]}\\n\")\n",
    "\n",
    "y_loc = y_blstm_train\n",
    "y_blstm = to_categorical(y_loc, num_classes=2)\n",
    "print(f\"location labels shape: {y_blstm.shape}\\n\")\n",
    "print(f\"BLSTM loc labels:\\n{y_loc[:5]}\\n\")\n",
    "\n",
    "y_emo = y_blstm_emo_train\n",
    "y_emo_blstm = to_categorical(y_emo, num_classes=NUM_EMOJI_TYPES + 1)\n",
    "print(f\"emo labels shape: {y_emo_blstm.shape}\\n\")\n",
    "print(f\"BLSTM emo labels:\\n{y_emo[:5]}\\n\")\n",
    "\n",
    "def calc_sample_weights(y):\n",
    "#     print(np.unique(y))\n",
    "    weights = class_weight.compute_class_weight('balanced', np.unique(y), y.flatten())\n",
    "    class_weight_dict = dict(enumerate(weights))\n",
    "#     print(f\"class weight dict:\\n{class_weight_dict}\\n\")\n",
    "    vfunc = np.vectorize(lambda x: class_weight_dict[x])\n",
    "    return vfunc(y)\n",
    "\n",
    "sample_weights_loc = calc_sample_weights(y_loc)\n",
    "print(f\"sample_weights_loc shape: {sample_weights_loc.shape}\")\n",
    "print(f\"sample_weights_loc examples:\\n{sample_weights_loc[:5]}\\n\")\n",
    "\n",
    "sample_weights_emo = calc_sample_weights(y_emo)\n",
    "print(f\"sample_weights_emo shape: {sample_weights_emo.shape}\")\n",
    "print(f\"sample_weights_emo examples:\\n{sample_weights_emo[:5]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_embedding_matrix(glove_size):\n",
    "    embeddings_index = {}\n",
    "    f = open(os.path.join(GLOVE_DIR, GLOVE_FILE_NAME + str(glove_size) + GLOVE_FILE_NAME_EXT), encoding=\"utf8\")\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "    embedding_matrix = np.zeros((vocab_size, glove_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= vocab_size - 1:\n",
    "            break\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i + 1] = embedding_vector\n",
    "\n",
    "    print(f\"embedding matrix shape {embedding_matrix.shape}\")\n",
    "    \n",
    "    return embedding_matrix\n",
    "\n",
    "gloves_dict = {}\n",
    "\n",
    "def get_embedding_matrix(glove_size):\n",
    "    global gloves_dict\n",
    "    \n",
    "    if gloves_dict[glove_size] is None:\n",
    "        gloves_dict[glove_size] = load_embedding_matrix(glove_size)\n",
    "        \n",
    "    return gloves_dict[glove_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Train model\n",
    " \n",
    " The following code is used to create and train a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def get_param_str(embedding_size, hidden_size, n_classes, input_size):\n",
    "    param_str = \"CLA-\" + str(n_classes) + \"_INP-\" + str(input_size) + \"_EMB-\" + str(embedding_size) + \"_HID-\" + str(hidden_size)\n",
    "    return param_str\n",
    "\n",
    "def get_blstm_file_name(embedding_size, hidden_size, n_classes, input_size):\n",
    "    param_str = get_param_str(embedding_size, hidden_size, n_classes, input_size)\n",
    "    return MODEL_DIR + BLSTM_BASE_FILE_NAME + param_str + BLSTM_FILE_NAME_EXT\n",
    "\n",
    "def save_blstm(blstm, embedding_size, hidden_size, n_classes=2, input_size=TWEET_NUM):\n",
    "    blstm.save(get_blstm_file_name(embedding_size, hidden_size, n_classes, input_size))\n",
    "\n",
    "def load_blstm(embedding_size, hidden_size, n_classes=2, input_size=TWEET_NUM):\n",
    "    return load_model(get_blstm_file_name(embedding_size, hidden_size, n_classes, input_size))\n",
    "\n",
    "def get_callbacks():\n",
    "    callbacks = []\n",
    "    \n",
    "    callbacks.append(EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=EARLY_STOPPING_PATIENCE,\n",
    "                              verbose=0, mode='auto'))\n",
    "    checkpoint_path = MODEL_DIR + BLSTM_BASE_FILE_NAME + \"check\" + BLSTM_FILE_NAME_EXT\n",
    "    callbacks.append(ModelCheckpoint(filepath=checkpoint_path, save_best_only=True))\n",
    "    \n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dropout\n",
    "\n",
    "def get_bi_lstm_model(embedding_size=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE, n_classes=2, use_glove=True,\n",
    "                      n_timesteps=N_TIMESTEPS, mode=\"concat\"):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if use_glove:\n",
    "        embedding_matrix = get_embedding_matrix(embedding_size)\n",
    "        model.add(Embedding(embedding_matrix.shape[0],\n",
    "                            embedding_matrix.shape[1],\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=N_TIMESTEPS,\n",
    "                            trainable=True))\n",
    "    else:\n",
    "        model.add(Embedding(vocab_size_size,\n",
    "                            embedding_size,\n",
    "                            input_length=N_TIMESTEPS))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(hidden_size, return_sequences=True), merge_mode=mode))\n",
    "    model.add(TimeDistributed(Dense(n_classes, activation='softmax')))\n",
    "#     binary_crossentropy\n",
    "#     categorical_crossentropy\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"], sample_weight_mode=\"temporal\")\n",
    "    return model\n",
    "\n",
    "def get_predictions(blstm, texts):\n",
    "    text_to_integer_sequences = tokenizer.texts_to_sequences(texts)\n",
    "    blstm_input = pad_sequences(text_to_integer_sequences, maxlen=N_TIMESTEPS, padding='post')\n",
    "    ypred = blstm.predict_classes(blstm_input)\n",
    "    return ypred\n",
    "\n",
    "def evaluate_blstm(blstm, texts=X_blstm_test, labels=y_blstm_test):\n",
    "    predictions = get_predictions(blstm, texts)\n",
    "#     print(predictions.shape)\n",
    "#     print(labels.shape)\n",
    "    print()\n",
    "    for i in range(10):\n",
    "        print(predictions[i])\n",
    "        print(labels[i])\n",
    "        print()\n",
    "    print_scores(calc_scores(predictions.flatten(), labels.flatten(), np.max(labels)>1))\n",
    "    print()\n",
    "\n",
    "def do_blstm_test(embedding_size, hidden_size, is_emo=False, use_glove=True, input_size=TWEET_NUM):\n",
    "    global blstm\n",
    "    \n",
    "    if is_emo:\n",
    "        y_train = y_emo_blstm\n",
    "        y_test = y_blstm_emo_test\n",
    "        sample_weights = sample_weights_emo\n",
    "    else:\n",
    "        y_train = y_blstm\n",
    "        y_test = y_blstm_test\n",
    "        sample_weights = sample_weights_loc\n",
    "        \n",
    "    n_classes = y_train.shape[2]\n",
    "    blstm = get_bi_lstm_model(embedding_size, hidden_size, n_classes, use_glove=use_glove)\n",
    "    print(f\"\\nTraining with embedding {embedding_size} hidden {hidden_size} classes {n_classes} input {input_size} glove {use_glove}\")    \n",
    "    blstm.fit(X_blstm, y_train, epochs=MAX_EPOCH,\n",
    "              validation_split=VALIDATION_SPLIT, verbose=2,\n",
    "              sample_weight=sample_weights, callbacks=get_callbacks())\n",
    "    save_blstm(blstm, embedding_size, hidden_size, n_classes, input_size)\n",
    "    try:\n",
    "        evaluate_blstm(blstm, labels=y_test)\n",
    "    except Exception:\n",
    "        print(\"couldn't evaluate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_blstm_test(200, 500, is_emo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n",
      "embedding matrix shape (137097, 50)\n",
      "\n",
      "Training with embedding 50 hidden 20 classes 2 input 473459 glove True\n",
      "Train on 340890 samples, validate on 37877 samples\n",
      "Epoch 1/30\n",
      " - 911s - loss: 0.3501 - acc: 0.7824 - val_loss: 0.3193 - val_acc: 0.8054\n",
      "Epoch 2/30\n",
      " - 898s - loss: 0.3148 - acc: 0.8146 - val_loss: 0.3061 - val_acc: 0.8259\n",
      "Epoch 3/30\n",
      " - 898s - loss: 0.3023 - acc: 0.8253 - val_loss: 0.2975 - val_acc: 0.8394\n",
      "Epoch 4/30\n",
      " - 906s - loss: 0.2942 - acc: 0.8322 - val_loss: 0.2946 - val_acc: 0.8386\n",
      "Epoch 5/30\n",
      " - 906s - loss: 0.2878 - acc: 0.8376 - val_loss: 0.2940 - val_acc: 0.8428\n",
      "Epoch 6/30\n",
      " - 905s - loss: 0.2828 - acc: 0.8416 - val_loss: 0.2952 - val_acc: 0.8402\n",
      "Epoch 7/30\n",
      " - 910s - loss: 0.2781 - acc: 0.8456 - val_loss: 0.2940 - val_acc: 0.8475\n",
      "(94692, 31)\n",
      "(94692, 31)\n",
      "[[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "couldn't evaluate\n",
      "\n",
      "Training with embedding 50 hidden 20 classes 21 input 473459 glove True\n",
      "Train on 340890 samples, validate on 37877 samples\n",
      "Epoch 1/30\n",
      " - 922s - loss: 2.6953 - acc: 0.5837 - val_loss: 2.5082 - val_acc: 0.5691\n",
      "Epoch 2/30\n",
      " - 918s - loss: 2.5143 - acc: 0.5899 - val_loss: 2.4312 - val_acc: 0.5993\n",
      "Epoch 3/30\n",
      " - 920s - loss: 2.4405 - acc: 0.5949 - val_loss: 2.3927 - val_acc: 0.5923\n",
      "Epoch 4/30\n",
      " - 917s - loss: 2.3892 - acc: 0.5982 - val_loss: 2.3700 - val_acc: 0.5894\n",
      "Epoch 5/30\n",
      " - 917s - loss: 2.3430 - acc: 0.5993 - val_loss: 2.3635 - val_acc: 0.5998\n",
      "Epoch 6/30\n",
      " - 919s - loss: 2.3042 - acc: 0.5995 - val_loss: 2.3543 - val_acc: 0.6018\n",
      "Epoch 7/30\n",
      " - 917s - loss: 2.2658 - acc: 0.5992 - val_loss: 2.3618 - val_acc: 0.6070\n",
      "Epoch 8/30\n",
      " - 914s - loss: 2.2324 - acc: 0.5996 - val_loss: 2.3716 - val_acc: 0.6021\n",
      "(94692, 31)\n",
      "(94692, 31)\n",
      "[[13 13 13 13 13 13 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0 13  7 13 13  7 12 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 8  8  8  8  8  8  8  8 11  8  8  8  8  8  8  8  8  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [19 19 10 10 10 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 1 14  4  4  4  4  4  4 10 10  1  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [20 20  3  3 14  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  6  6  6  6  0  6  6  6  6  6  1  6  6  1  6  6  6  6  6  6\n",
      "   0  0  0  0  0  0  0]\n",
      " [13 13 13 13 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0 15  8  4  4  4  9  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]]\n",
      "[[0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "couldn't evaluate\n",
      "\n",
      "Training with embedding 50 hidden 50 classes 2 input 473459 glove True\n",
      "Train on 340890 samples, validate on 37877 samples\n",
      "Epoch 1/30\n",
      " - 906s - loss: 0.3413 - acc: 0.7886 - val_loss: 0.3095 - val_acc: 0.8186\n",
      "Epoch 2/30\n",
      " - 903s - loss: 0.3078 - acc: 0.8207 - val_loss: 0.2983 - val_acc: 0.8302\n",
      "Epoch 3/30\n",
      " - 904s - loss: 0.2955 - acc: 0.8311 - val_loss: 0.2937 - val_acc: 0.8418\n",
      "Epoch 4/30\n",
      " - 906s - loss: 0.2873 - acc: 0.8377 - val_loss: 0.2894 - val_acc: 0.8406\n",
      "Epoch 5/30\n",
      " - 903s - loss: 0.2809 - acc: 0.8428 - val_loss: 0.2897 - val_acc: 0.8504\n",
      "Epoch 6/30\n",
      " - 907s - loss: 0.2752 - acc: 0.8472 - val_loss: 0.2906 - val_acc: 0.8511\n",
      "(94692, 31)\n",
      "(94692, 31)\n",
      "[[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "couldn't evaluate\n",
      "\n",
      "Training with embedding 50 hidden 50 classes 21 input 473459 glove True\n",
      "Train on 340890 samples, validate on 37877 samples\n",
      "Epoch 1/30\n",
      " - 918s - loss: 2.6599 - acc: 0.5836 - val_loss: 2.4722 - val_acc: 0.5729\n",
      "Epoch 2/30\n",
      " - 926s - loss: 2.4803 - acc: 0.5931 - val_loss: 2.3951 - val_acc: 0.5898\n",
      "Epoch 3/30\n",
      " - 918s - loss: 2.4045 - acc: 0.5961 - val_loss: 2.3600 - val_acc: 0.6012\n",
      "Epoch 4/30\n",
      " - 916s - loss: 2.3515 - acc: 0.5973 - val_loss: 2.3386 - val_acc: 0.6075\n",
      "Epoch 5/30\n",
      " - 919s - loss: 2.3018 - acc: 0.5999 - val_loss: 2.3345 - val_acc: 0.6075\n",
      "Epoch 6/30\n",
      " - 918s - loss: 2.2591 - acc: 0.5996 - val_loss: 2.3367 - val_acc: 0.6105\n",
      "Epoch 7/30\n",
      " - 917s - loss: 2.2174 - acc: 0.5997 - val_loss: 2.3390 - val_acc: 0.6090\n",
      "(94692, 31)\n",
      "(94692, 31)\n",
      "[[13  2  2 13 13 13 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0 13 13  7 13 13 12 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 8  8  8  8  8  8  8  8 11  8  8  8  8  8  8  8  8  8  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [19 10  1  2  2  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 1  1  1  4  4  1  4  4  4  4  4  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 3  5  3  3  3  3  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  2  2  6  6  2  0  0  0  0  6  0  1  1  6  6  1  6  4  6  6  6  6\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 2 13 12 12 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [14  0  4 14  4  9  9  9  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]]\n",
      "[[0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "couldn't evaluate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with embedding 50 hidden 100 classes 2 input 473459 glove True\n",
      "Train on 340890 samples, validate on 37877 samples\n",
      "Epoch 1/30\n",
      " - 913s - loss: 0.3377 - acc: 0.7908 - val_loss: 0.3067 - val_acc: 0.8233\n",
      "Epoch 2/30\n",
      " - 912s - loss: 0.3041 - acc: 0.8234 - val_loss: 0.2929 - val_acc: 0.8389\n",
      "Epoch 3/30\n",
      " - 910s - loss: 0.2917 - acc: 0.8341 - val_loss: 0.2886 - val_acc: 0.8453\n",
      "Epoch 4/30\n",
      " - 917s - loss: 0.2831 - acc: 0.8411 - val_loss: 0.2889 - val_acc: 0.8561\n",
      "Epoch 5/30\n",
      " - 913s - loss: 0.2766 - acc: 0.8460 - val_loss: 0.2862 - val_acc: 0.8537\n",
      "Epoch 6/30\n",
      " - 910s - loss: 0.2707 - acc: 0.8508 - val_loss: 0.2859 - val_acc: 0.8597\n",
      "Epoch 7/30\n",
      " - 917s - loss: 0.2657 - acc: 0.8548 - val_loss: 0.2871 - val_acc: 0.8594\n",
      "Epoch 8/30\n",
      " - 915s - loss: 0.2612 - acc: 0.8580 - val_loss: 0.2909 - val_acc: 0.8663\n",
      "(94692, 31)\n",
      "(94692, 31)\n",
      "[[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "couldn't evaluate\n",
      "\n",
      "Training with embedding 50 hidden 100 classes 21 input 473459 glove True\n",
      "Train on 340890 samples, validate on 37877 samples\n",
      "Epoch 1/30\n",
      " - 928s - loss: 2.6383 - acc: 0.5852 - val_loss: 2.4584 - val_acc: 0.5938\n",
      "Epoch 2/30\n",
      " - 932s - loss: 2.4602 - acc: 0.5990 - val_loss: 2.3790 - val_acc: 0.6032\n",
      "Epoch 3/30\n",
      " - 922s - loss: 2.3868 - acc: 0.6058 - val_loss: 2.3447 - val_acc: 0.6087\n",
      "Epoch 4/30\n",
      " - 925s - loss: 2.3305 - acc: 0.6087 - val_loss: 2.3263 - val_acc: 0.6068\n",
      "Epoch 5/30\n",
      " - 930s - loss: 2.2814 - acc: 0.6097 - val_loss: 2.3208 - val_acc: 0.6099\n",
      "Epoch 6/30\n",
      " - 924s - loss: 2.2365 - acc: 0.6090 - val_loss: 2.3256 - val_acc: 0.6138\n",
      "Epoch 7/30\n",
      " - 929s - loss: 2.1944 - acc: 0.6086 - val_loss: 2.3335 - val_acc: 0.6197\n",
      "(94692, 31)\n",
      "(94692, 31)\n",
      "[[ 9  9  9  9  9  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0 13  7  7  7  7  7  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 8  8  8  8  8  8  8  8 11  8  8  8  8  8  8  8  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [11 10 10 10 10 10 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  4  4  1  1  1  4  4  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 3  3  3  3  3  3  3  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  2  6  6  0  0  6  6  6  0  1  1  6  6  9  4  6  6  6  6  6\n",
      "   6  6  0  0  0  0  0]\n",
      " [ 7 13  7  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  4  4  2  2  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]]\n",
      "[[0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "couldn't evaluate\n",
      "Found 1193514 word vectors.\n",
      "embedding matrix shape (137097, 25)\n",
      "\n",
      "Training with embedding 25 hidden 20 classes 2 input 473459 glove True\n",
      "Train on 340890 samples, validate on 37877 samples\n",
      "Epoch 1/30\n",
      " - 880s - loss: 0.3598 - acc: 0.7699 - val_loss: 0.3272 - val_acc: 0.7914\n",
      "Epoch 2/30\n",
      " - 883s - loss: 0.3259 - acc: 0.8036 - val_loss: 0.3136 - val_acc: 0.8011\n",
      "Epoch 3/30\n",
      " - 892s - loss: 0.3139 - acc: 0.8152 - val_loss: 0.3067 - val_acc: 0.8124\n",
      "Epoch 4/30\n",
      " - 881s - loss: 0.3059 - acc: 0.8224 - val_loss: 0.3054 - val_acc: 0.8116\n",
      "Epoch 5/30\n",
      " - 1093s - loss: 0.3006 - acc: 0.8270 - val_loss: 0.3010 - val_acc: 0.8205\n",
      "Epoch 6/30\n",
      " - 1343s - loss: 0.2963 - acc: 0.8307 - val_loss: 0.3018 - val_acc: 0.8205\n",
      "Epoch 7/30\n",
      " - 883s - loss: 0.2926 - acc: 0.8340 - val_loss: 0.3009 - val_acc: 0.8123\n",
      "Epoch 8/30\n",
      " - 870s - loss: 0.2893 - acc: 0.8365 - val_loss: 0.3005 - val_acc: 0.8159\n",
      "Epoch 9/30\n",
      " - 889s - loss: 0.2866 - acc: 0.8390 - val_loss: 0.2977 - val_acc: 0.8253\n",
      "Epoch 10/30\n",
      " - 887s - loss: 0.2844 - acc: 0.8405 - val_loss: 0.2974 - val_acc: 0.8182\n",
      "Epoch 11/30\n",
      " - 882s - loss: 0.2822 - acc: 0.8422 - val_loss: 0.2968 - val_acc: 0.8264\n",
      "Epoch 12/30\n",
      " - 880s - loss: 0.2802 - acc: 0.8439 - val_loss: 0.2994 - val_acc: 0.8245\n",
      "Epoch 13/30\n",
      " - 878s - loss: 0.2783 - acc: 0.8451 - val_loss: 0.3034 - val_acc: 0.8214\n",
      "(94692, 31)\n",
      "(94692, 31)\n",
      "[[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "couldn't evaluate\n",
      "\n",
      "Training with embedding 25 hidden 20 classes 21 input 473459 glove True\n",
      "Train on 340890 samples, validate on 37877 samples\n",
      "Epoch 1/30\n",
      " - 894s - loss: 2.7563 - acc: 0.5840 - val_loss: 2.5692 - val_acc: 0.5749\n",
      "Epoch 2/30\n",
      " - 902s - loss: 2.5784 - acc: 0.5861 - val_loss: 2.4803 - val_acc: 0.5732\n",
      "Epoch 3/30\n",
      " - 891s - loss: 2.5108 - acc: 0.5862 - val_loss: 2.4373 - val_acc: 0.5771\n",
      "Epoch 4/30\n",
      " - 889s - loss: 2.4662 - acc: 0.5866 - val_loss: 2.4098 - val_acc: 0.5798\n",
      "Epoch 5/30\n",
      " - 892s - loss: 2.4276 - acc: 0.5877 - val_loss: 2.3929 - val_acc: 0.5801\n",
      "Epoch 6/30\n",
      " - 891s - loss: 2.3967 - acc: 0.5888 - val_loss: 2.3802 - val_acc: 0.5860\n",
      "Epoch 7/30\n",
      " - 889s - loss: 2.3673 - acc: 0.5902 - val_loss: 2.3810 - val_acc: 0.5915\n",
      "Epoch 8/30\n",
      " - 886s - loss: 2.3419 - acc: 0.5899 - val_loss: 2.3678 - val_acc: 0.5876\n",
      "Epoch 9/30\n",
      " - 905s - loss: 2.3181 - acc: 0.5899 - val_loss: 2.3729 - val_acc: 0.5984\n",
      "Epoch 10/30\n",
      " - 897s - loss: 2.2990 - acc: 0.5889 - val_loss: 2.3735 - val_acc: 0.5868\n",
      "(94692, 31)\n",
      "(94692, 31)\n",
      "[[ 2  9 13 13 13 13 13 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 7  7  5  7  7 13  7  7  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 8  8  8  8  8  8  8  8 11  8  8  8  8 11 11 18 18  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [19 19 14 10 10 10 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [14 14 14 14  4  4  4  4  4 10 10  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 9  9  9  9  9  9  9  9  9  9  9  9  9  9  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 3  3  3 16  2  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  8  2  6  6  6  6  6  6  6  6  6  6  6  1  6  4  4  4 10 10 10 10 10\n",
      "   0  0  0  0  0  0  0]\n",
      " [13 13 13 13 13 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 1  8  4  8  4  4  4  2  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]]\n",
      "[[0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "couldn't evaluate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with embedding 25 hidden 50 classes 2 input 473459 glove True\n",
      "Train on 340890 samples, validate on 37877 samples\n",
      "Epoch 1/30\n",
      " - 882s - loss: 0.3518 - acc: 0.7772 - val_loss: 0.3187 - val_acc: 0.8079\n",
      "Epoch 2/30\n",
      " - 882s - loss: 0.3184 - acc: 0.8107 - val_loss: 0.3079 - val_acc: 0.8195\n",
      "Epoch 3/30\n",
      " - 883s - loss: 0.3075 - acc: 0.8212 - val_loss: 0.3001 - val_acc: 0.8225\n",
      "Epoch 4/30\n",
      " - 879s - loss: 0.2996 - acc: 0.8282 - val_loss: 0.2965 - val_acc: 0.8241\n",
      "Epoch 5/30\n",
      " - 882s - loss: 0.2939 - acc: 0.8328 - val_loss: 0.2942 - val_acc: 0.8461\n",
      "Epoch 6/30\n",
      " - 885s - loss: 0.2890 - acc: 0.8369 - val_loss: 0.2925 - val_acc: 0.8370\n",
      "Epoch 7/30\n",
      " - 885s - loss: 0.2851 - acc: 0.8401 - val_loss: 0.2918 - val_acc: 0.8357\n",
      "Epoch 8/30\n",
      " - 876s - loss: 0.2816 - acc: 0.8429 - val_loss: 0.2906 - val_acc: 0.8453\n",
      "Epoch 9/30\n",
      " - 1000s - loss: 0.2787 - acc: 0.8452 - val_loss: 0.2936 - val_acc: 0.8461\n",
      "Epoch 10/30\n",
      " - 967s - loss: 0.2760 - acc: 0.8473 - val_loss: 0.2926 - val_acc: 0.8384\n",
      "(94692, 31)\n",
      "(94692, 31)\n",
      "[[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "couldn't evaluate\n",
      "\n",
      "Training with embedding 25 hidden 50 classes 21 input 473459 glove True\n",
      "Train on 340890 samples, validate on 37877 samples\n",
      "Epoch 1/30\n",
      " - 929s - loss: 2.7143 - acc: 0.5798 - val_loss: 2.5299 - val_acc: 0.5704\n",
      "Epoch 2/30\n",
      " - 3787s - loss: 2.5477 - acc: 0.5873 - val_loss: 2.4524 - val_acc: 0.5799\n",
      "Epoch 3/30\n",
      " - 914s - loss: 2.4815 - acc: 0.5915 - val_loss: 2.4106 - val_acc: 0.5866\n",
      "Epoch 4/30\n",
      " - 914s - loss: 2.4341 - acc: 0.5960 - val_loss: 2.3837 - val_acc: 0.6018\n",
      "Epoch 5/30\n",
      " - 915s - loss: 2.3966 - acc: 0.5985 - val_loss: 2.3681 - val_acc: 0.5852\n",
      "Epoch 6/30\n",
      " - 923s - loss: 2.3650 - acc: 0.5982 - val_loss: 2.3544 - val_acc: 0.5901\n",
      "Epoch 7/30\n",
      " - 919s - loss: 2.3332 - acc: 0.5982 - val_loss: 2.3609 - val_acc: 0.5840\n",
      "Epoch 8/30\n",
      " - 928s - loss: 2.3017 - acc: 0.5980 - val_loss: 2.3585 - val_acc: 0.5908\n",
      "(94692, 31)\n",
      "(94692, 31)\n",
      "[[16  4  2  9 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 5  5 16  7  7  7  7  7 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 8  8  8  8  8  8  8  8 11  8  8  8  8  8  8  8  8  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [19  3 14 10 10 10  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 1  4  4 14 14 14  4  4  4  4 10  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [16 16 16  3  3  3  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  6  6  0 17 17  0  0  0  6  6  6  6  1  4  1  4  4  4  6  6  6  6\n",
      "   0  0  0  0  0  0  0]\n",
      " [13 13 13  7 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [14  8  8  8  2  4  2  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]]\n",
      "[[0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "couldn't evaluate\n",
      "\n",
      "Training with embedding 25 hidden 100 classes 2 input 473459 glove True\n",
      "Train on 340890 samples, validate on 37877 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f654e2f9f1ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0membedding_size\u001b[0m \u001b[1;32min\u001b[0m \u001b[0membedding_sizes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhidden_sizes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mdo_blstm_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_emo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mdo_blstm_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_emo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-8c273b6c3b56>\u001b[0m in \u001b[0;36mdo_blstm_test\u001b[1;34m(embedding_size, hidden_size, is_emo, use_glove, input_size)\u001b[0m\n\u001b[0;32m     63\u001b[0m     blstm.fit(X_blstm, y_train, epochs=MAX_EPOCH,\n\u001b[0;32m     64\u001b[0m               \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVALIDATION_SPLIT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m               sample_weight=sample_weights, callbacks=get_callbacks())\n\u001b[0m\u001b[0;32m     66\u001b[0m     \u001b[0msave_blstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblstm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 908\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    909\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1141\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1143\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1144\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1324\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1325\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1328\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1330\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1313\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1315\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1421\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1422\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1423\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedding_sizes = [50, 25, 100]\n",
    "hidden_sizes = [20, 50, 100]\n",
    "\n",
    "blstm = None\n",
    "for embedding_size in embedding_sizes:\n",
    "    for hidden_size in hidden_sizes:\n",
    "        do_blstm_test(embedding_size, hidden_size, is_emo=False)\n",
    "        do_blstm_test(embedding_size, hidden_size, is_emo=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blstm = load_blstm(200, 1000, 2)\n",
    "blstm_emo = load_blstm(200, 500, 21)\n",
    "imtired = 20\n",
    "inputs = X_blstm_test[:imtired]\n",
    "for i in range(imtired):\n",
    "    print(inputs[i])\n",
    "labels = y_blstm_test[:imtired]\n",
    "labels_emo = y_blstm_emo_test[:imtired]\n",
    "\n",
    "evaluate_blstm(blstm, inputs, labels)\n",
    "evaluate_blstm(blstm_emo, inputs, labels_emo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_blstm_test(200, 500, is_emo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_blstm(blstm, labels=y_blstm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_blstm(blstm, EMBEDDING_SIZE, HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for embedding_size in embedding_sizes:\n",
    "    for hidden_size in hidden_sizes:\n",
    "        blstm = load_blstm(embedding_size, hidden_size, 2, 100000)\n",
    "        evaluate_blstm(blstm, labels=y_blstm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for embedding_size in embedding_sizes:\n",
    "    for hidden_size in hidden_sizes:\n",
    "        blstm = load_blstm(embedding_size, hidden_size)\n",
    "        print(f\"\\nEmbedding {embedding_size} hidden {hidden_size}\")\n",
    "        evaluate_blstm(blstm, X_blstm_test, y_blstm_test)\n",
    "        print(f\"test:\")\n",
    "        evaluate_blstm(blstm, X_blstm_test, y_blstm_test)\n",
    "        print(f\"\\ntrain:\")\n",
    "        evaluate_blstm(blstm, X_blstm_train, y_blstm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blstm_model_CLA-21_INP-473459_EMB-200_HID-500.h5\n",
      "\n",
      "[ 5  7  7  2 13 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 5  5 20  5  7 16 16  7  7 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 8  8  8  8  8  8  8  8 11  8  8  8  8  8  8  8  8  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[19 19 14 10 10 10 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 1  1  1  1  4  1  4  4  4 14 14 14  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[9 9 9 9 9 9 9 9 9 9 9 9 9 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[16 16  1 16 11  7  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 0  0 17  0  6 17 17 17  0  0  0  0  0  1  1  1  2  1  4 10  4  6  6 14\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[11  7 13 13 13 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 9  9 10  2  2 14  2  2  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 0.9386140192379232\n",
      "Precision: 0.23498124513206795\n",
      "Recall: 0.025784433985785338\n",
      "F1: 0.03654908395816315\n",
      "\n",
      "blstm_model_CLA-21_INP-473459_EMB-25_HID-20.h5\n",
      "\n",
      "[ 2  9 13 13 13 13 13 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 7  7  5  7  7 13  7  7  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 8  8  8  8  8  8  8  8 11  8  8  8  8 11 11 18 18  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[19 19 14 10 10 10 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[14 14 14 14  4  4  4  4  4 10 10  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[9 9 9 9 9 9 9 9 9 9 9 9 9 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 3  3  3 16  2  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 0  8  2  6  6  6  6  6  6  6  6  6  6  6  1  6  4  4  4 10 10 10 10 10\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[13 13 13 13 13 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 8 4 8 4 4 4 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 0.9386888742630889\n",
      "Precision: 0.247092789303449\n",
      "Recall: 0.02537206790445387\n",
      "F1: 0.036161071451996644\n",
      "\n",
      "blstm_model_CLA-21_INP-473459_EMB-25_HID-50.h5\n",
      "\n",
      "[16  4  2  9 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 5  5 16  7  7  7  7  7 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 8  8  8  8  8  8  8  8 11  8  8  8  8  8  8  8  8  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[19  3 14 10 10 10  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 1  4  4 14 14 14  4  4  4  4 10  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[16 16 16  3  3  3  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 0  0  6  6  0 17 17  0  0  0  6  6  6  6  1  4  1  4  4  4  6  6  6  6\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[13 13 13  7 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[14  8  8  8  2  4  2  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 0.9394850524520503\n",
      "Precision: 0.24809226222672137\n",
      "Recall: 0.026962316485438998\n",
      "F1: 0.038654007496429325\n",
      "\n",
      "blstm_model_CLA-21_INP-473459_EMB-50_HID-100.h5\n",
      "\n",
      "[9 9 9 9 9 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 0 13  7  7  7  7  7  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 8  8  8  8  8  8  8  8 11  8  8  8  8  8  8  8  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[11 10 10 10 10 10 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 4 4 1 1 1 4 4 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 2 6 6 0 0 6 6 6 0 1 1 6 6 9 4 6 6 6 6 6 6 6 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 7 13  7  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 4 4 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 0.9408742893039009\n",
      "Precision: 0.25814429741603273\n",
      "Recall: 0.0290343671683421\n",
      "F1: 0.04270304344795807\n",
      "\n",
      "blstm_model_CLA-21_INP-473459_EMB-50_HID-20.h5\n",
      "\n",
      "[13 13 13 13 13 13 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 0 13  7 13 13  7 12 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 8  8  8  8  8  8  8  8 11  8  8  8  8  8  8  8  8  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[19 19 10 10 10 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 1 14  4  4  4  4  4  4 10 10  1  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[20 20  3  3 14  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 6 6 6 6 0 6 6 6 6 6 1 6 6 1 6 6 6 6 6 6 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[13 13 13 13 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 0  0 15  8  4  4  4  9  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9400932235762441\n",
      "Precision: 0.24999451388985403\n",
      "Recall: 0.026570847229349326\n",
      "F1: 0.038197040433274335\n",
      "\n",
      "blstm_model_CLA-21_INP-473459_EMB-50_HID-50.h5\n",
      "\n",
      "[13  2  2 13 13 13 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 0 13 13  7 13 13 12 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 8  8  8  8  8  8  8  8 11  8  8  8  8  8  8  8  8  8  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[19 10  1  2  2  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 1 1 4 4 1 4 4 4 4 4 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[3 5 3 3 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 2 2 6 6 2 0 0 0 0 6 0 1 1 6 6 1 6 4 6 6 6 6 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 2 13 12 12 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[14  0  4 14  4  9  9  9  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 0.9401702912889606\n",
      "Precision: 0.25727803363457447\n",
      "Recall: 0.027671985152310095\n",
      "F1: 0.04052694442023445\n",
      "\n",
      "blstm_model_CLA-2_INP-100000_EMB-100_HID-200.h5\n",
      "\n",
      "[1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 0.7886318699811817\n",
      "Precision: 0.7516284955605343\n",
      "Recall: 0.10831879625518888\n",
      "F1: 0.18934996282926153\n",
      "ratio of positive/negative predictions 0.22789641935892666\n",
      "\n",
      "blstm_model_CLA-2_INP-100000_EMB-100_HID-500.h5\n",
      "\n",
      "[1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 0.8155531073238466\n",
      "Precision: 0.7010932702680276\n",
      "Recall: 0.11649422880375865\n",
      "F1: 0.19979101914376968\n",
      "ratio of positive/negative predictions 0.19765576136145302\n",
      "\n",
      "blstm_model_CLA-2_INP-100000_EMB-200_HID-1000.h5\n",
      "\n",
      "[1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 0.8290000994736074\n",
      "Precision: 0.6487947058335408\n",
      "Recall: 0.1178719763611557\n",
      "F1: 0.19949925047044936\n",
      "ratio of positive/negative predictions 0.1807735231235258\n",
      "\n",
      "blstm_model_CLA-2_INP-100000_EMB-200_HID-200.h5\n",
      "\n",
      "[1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 0.8187260428717622\n",
      "Precision: 0.7005850136918098\n",
      "Recall: 0.11832928344052264\n",
      "F1: 0.20246251152194603\n",
      "ratio of positive/negative predictions 0.19444944083568733\n",
      "\n",
      "blstm_model_CLA-2_INP-100000_EMB-200_HID-500.h5\n",
      "\n",
      "[0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 1 1 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8058455733563349\n",
      "Precision: 0.6808459878848229\n",
      "Recall: 0.10852991314498488\n",
      "F1: 0.18721665010004152\n",
      "ratio of positive/negative predictions 0.2060333468235897\n",
      "\n",
      "blstm_model_CLA-2_INP-473459_EMB-100_HID-1000.h5\n",
      "\n",
      "[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 0.8872098743225916\n",
      "Precision: 0.6891233092689404\n",
      "Recall: 0.1807534090043422\n",
      "F1: 0.2863885991154486\n",
      "ratio of positive/negative predictions 0.1252127440680345\n",
      "\n",
      "blstm_model_CLA-2_INP-473459_EMB-100_HID-200.h5\n",
      "\n",
      "[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 0.8662662513302891\n",
      "Precision: 0.8133453655298315\n",
      "Recall: 0.17310209785269776\n",
      "F1: 0.2854521792153186\n",
      "ratio of positive/negative predictions 0.15431592817733011\n",
      "\n",
      "blstm_model_CLA-2_INP-473459_EMB-100_HID-500.h5\n",
      "\n",
      "[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 0.8689571486776142\n",
      "Precision: 0.774251099493818\n",
      "Recall: 0.17059536053022512\n",
      "F1: 0.27958753310185447\n",
      "ratio of positive/negative predictions 0.14905711283986248\n",
      "\n",
      "blstm_model_CLA-2_INP-473459_EMB-200_HID-1000.h5\n",
      "\n",
      "[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 0.8836053187038998\n",
      "Precision: 0.7128557796033524\n",
      "Recall: 0.17957320498650425\n",
      "F1: 0.28687951477810403\n",
      "ratio of positive/negative predictions 0.13037617375450186\n",
      "\n",
      "blstm_model_CLA-2_INP-473459_EMB-200_HID-200.h5\n",
      "\n",
      "[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 0.8648395545217568\n",
      "Precision: 0.7992593975603685\n",
      "Recall: 0.16955324902796512\n",
      "F1: 0.2797589980884678\n",
      "ratio of positive/negative predictions 0.15481738417116\n",
      "\n",
      "blstm_model_CLA-2_INP-473459_EMB-200_HID-500.h5\n",
      "\n",
      "[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8669686985172982\n",
      "Precision: 0.7892291096174592\n",
      "Recall: 0.1704957705450675\n",
      "F1: 0.2804141644385396\n",
      "ratio of positive/negative predictions 0.15202939785763828\n",
      "\n",
      "blstm_model_CLA-2_INP-473459_EMB-25_HID-20.h5\n",
      "\n",
      "[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 0.8259269781962029\n",
      "Precision: 0.8522218073188947\n",
      "Recall: 0.14192680217724396\n",
      "F1: 0.24333005086590503\n",
      "ratio of positive/negative predictions 0.19720881145390898\n",
      "\n",
      "blstm_model_CLA-2_INP-473459_EMB-25_HID-50.h5\n",
      "\n",
      "[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 0.8408854922512785\n",
      "Precision: 0.8287382789809974\n",
      "Recall: 0.15061861519928968\n",
      "F1: 0.2549089360263022\n",
      "ratio of positive/negative predictions 0.18070777515694347\n",
      "\n",
      "blstm_model_CLA-2_INP-473459_EMB-50_HID-100.h5\n",
      "\n",
      "[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 0.8741117211250601\n",
      "Precision: 0.771066716455066\n",
      "Recall: 0.17623546425480968\n",
      "F1: 0.2868974726608557\n",
      "ratio of positive/negative predictions 0.14369337328629458\n",
      "\n",
      "blstm_model_CLA-2_INP-473459_EMB-50_HID-20.h5\n",
      "\n",
      "[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 0.8541348998382532\n",
      "Precision: 0.8103061986557132\n",
      "Recall: 0.1600780308680934\n",
      "F1: 0.2673419800828172\n",
      "ratio of positive/negative predictions 0.1662476511283441\n",
      "\n",
      "blstm_model_CLA-2_INP-473459_EMB-50_HID-50.h5\n",
      "\n",
      "[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy: 0.8531060974596076\n",
      "Precision: 0.796033524188864\n",
      "Recall: 0.15717211436061276\n",
      "F1: 0.2625126563226884\n",
      "ratio of positive/negative predictions 0.16633894882287292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "onlyfiles = [f for f in listdir(MODEL_DIR) if isfile(join(MODEL_DIR, f))]\n",
    "\n",
    "for file_path in onlyfiles:\n",
    "    blstm = load_model(MODEL_DIR + file_path)\n",
    "    if file_path[17] == \"1\":\n",
    "        y_test = y_blstm_emo_test\n",
    "    else:\n",
    "        y_test = y_blstm_test\n",
    "    print(file_path)\n",
    "    evaluate_blstm(blstm, X_blstm_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

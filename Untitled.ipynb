{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### 10 Emoji Prediction\n",
    "\n",
    "The task of this project is to make a system that would automatically fill the text with the appropriate emoticons. This can be done in two steps. First, for each position within the text a prediction is made whether an emoticon should be placed there. Second, an appropriate emoticon is chosen from a list of available emoticons. Both these tasks can be set up as supervised classification problems.\n",
    "\n",
    "Competition website:\n",
    "https://competitions.codalab.org/competitions/17344\n",
    "\n",
    "Dataset:\n",
    "https://competitions.codalab.org/competitions/17344\n",
    "\n",
    "Entry point:\n",
    "https://arxiv.org/pdf/1702.07285.pdf (Barbieri, Francesco, Miguel Ballesteros, and Horacio Saggion. Are Emojis Predictable?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Define paths to folders containing the data and the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# NUMBER_OF_TWEETS = \"ALL\"\n",
    "NUMBER_OF_TWEETS = 100000\n",
    "\n",
    "MAX_WORDS_PER_TWEET = 30\n",
    "DATA_LOCATION = \"./train/data/\"\n",
    "RESULT_LOCATION = \"./result/\"\n",
    "TWEET_FILE_NAME = \"tweet_by_ID_28_4_2018__03_20_05\" + \"_\"\n",
    "\n",
    "k = 3\n",
    "\n",
    "if NUMBER_OF_TWEETS is not None:\n",
    "    TWEET_FILE_NAME += str(NUMBER_OF_TWEETS)\n",
    "else:\n",
    "    TWEET_FILE_NAME += \"ALL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Load the data\n",
    "Tweets are loaded in two ways: list of strings (for the TF-IDF vectorizer) and a list of lists of words (for feature extraction). Labels are read as a numpy array of N * MAX_WORDS_PER_TWEET dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tweets 100000\n",
      "example of tweet texts:\n",
      "['lol west covina california', 'things got a little festive at the office christmas2016 redrock', 'step out and explore ellis island cafe', 'rupauls drag race bingo fun drag queens be sexy rupaulsdragrace user abwyman la', 'just light makeup blueeyes lupusgirl photography modelingagency modeling smiling']\n",
      "\n",
      "example of labels (emoji locations):\n",
      "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "base_file_name = DATA_LOCATION + TWEET_FILE_NAME\n",
    "\n",
    "text_lines = []\n",
    "text_lines_split = []\n",
    "\n",
    "with open(base_file_name + \".text\", 'r', encoding=\"utf-8\") as out_text:\n",
    "    for line in out_text:\n",
    "        text_lines.append(line[:-1])\n",
    "        text_lines_split.append(line[:-1].split())\n",
    "        \n",
    "loc_lines = []\n",
    "with open(base_file_name + \".loclabels\", 'r') as loc_labels:\n",
    "    for line in loc_labels:\n",
    "        loc_line = []\n",
    "        for c in line[:-1]:\n",
    "            loc_line.append(int(c))\n",
    "        loc_lines.append(loc_line)\n",
    "\n",
    "loc_lines = np.asarray(loc_lines)\n",
    "\n",
    "# full_text = open(base_file_name + \".full\", 'r')\n",
    "# emoji_labels = open(base_file_name + \".emolabels\", 'r')\n",
    "# emoji_ids = open(base_file_name + \".ids\", 'r')\n",
    "\n",
    "print(f\"number of tweets {len(text_lines)}\")\n",
    "print(f\"example of tweet texts:\\n{text_lines[:5]}\\n\")\n",
    "print(f\"example of labels (emoji locations):\\n{loc_lines[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### TF-IDF Feature Extraction\n",
    "TF-IDF is computed on the collection of tweets. Then for every position between words a new example is generated: a $2*k$ array containing the k left and k right tf-idf values of words. Labels are taken as 1 or 0 wether an emoji was there in the original tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import random\n",
    "\n",
    "word_to_tfidf_index_dict = {}\n",
    "tfidf_model = TfidfVectorizer(input=\"content\", analyzer=\"word\", stop_words=\"english\")\n",
    "X_tfidf_features = tfidf_model.fit_transform(text_lines)\n",
    "\n",
    "def tfidf_features(tweets, labels, k, func):\n",
    "    for i, word in enumerate(tfidf_model.get_feature_names()):\n",
    "        word_to_tfidf_index_dict[word] = i\n",
    "\n",
    "    print(f\"X shape {X_tfidf.shape}\")\n",
    "    print(f\"Y shape {loc_lines.shape}\")\n",
    "    print(f\"some tf-idf values\\n{X_tfidf[0]}\\n\")\n",
    "\n",
    "    N = len(tweets)\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for tweet_index, (tweet, label) in enumerate(zip(tweets, labels)):\n",
    "        for pos in range(len(tweet) + 1):\n",
    "                \n",
    "            x = []\n",
    "            for i in range(pos - k, pos + k):\n",
    "                if i < 0 or i >= len(tweet):\n",
    "                    x.append(0.0)\n",
    "                else:\n",
    "                    x.append(func(tweet_index, tweet[i]))\n",
    "            X.append(x)\n",
    "            y.append(label[pos])\n",
    "            \n",
    "    return np.asarray(X), np.asarray(y)\n",
    "\n",
    "def word_to_tfidf(tweet_index, word):\n",
    "    if word in word_to_tfidf_index_dict:\n",
    "        return X_tfidf_features[tweet_index, word_to_tfidf_index_dict[word]]\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def print_dataset(X, y):\n",
    "    emoji_num = np.count_nonzero(y)\n",
    "    class_freq_ratio = emoji_num / (X.shape[0] * X.shape[1])\n",
    "    \n",
    "    print(\"after feature extraction:\")\n",
    "    print(f\"X shape {X.shape}\")\n",
    "    print(f\"y shape {y.shape}\")\n",
    "    print(f\"some X values\\n{X[:5]}\")\n",
    "    print(f\"some y values\\n{y[:5]}\")\n",
    "    print(f\"non zero elements (1 in label) in y {emoji_num}\")\n",
    "    print(f\"class frequency ratio {class_freq_ratio}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vector Feature Extraction\n",
    "\n",
    "A similar dataset is obtained using w2vec. By setting the number of features to $2*k=6$, the dimensionality stays the same as the previous tf-idf feature extraction. For each word a 6 dimensional vector is obtained and then the average of the 6 neighboring words is taken. Labels stay the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "num_of_features = 2 * k\n",
    "w2v_model_file_name = \"w2v_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(text_lines_split, min_count=1, size=num_of_features)\n",
    "w2v_model.save(w2v_model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n",
      "[ 4.807096   5.3436766 -3.5083148  5.000165  -1.2895648  4.4985213]\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec.load(w2v_model_file_name)\n",
    "\n",
    "example = w2v_model.wv[\"california\"]\n",
    "print(example.shape)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def w2v_features(tweets, labels, k):\n",
    "    N = len(tweets)\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for tweet_index, (tweet, label) in enumerate(zip(tweets, labels)):\n",
    "        for pos in range(len(tweet) + 1):\n",
    "            x = []\n",
    "            for i in range(pos - k, pos + k):\n",
    "                if i < 0 or i >= len(tweet):\n",
    "                    x.append(np.zeros(num_of_features))\n",
    "                else:\n",
    "                    x.append(w2v_model.wv[tweet[i]])\n",
    "            x = np.average(x, axis=0)\n",
    "            X.append(x)\n",
    "            y.append(label[pos])\n",
    "            \n",
    "    return np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (1187039, 6)\n",
      "Y shape (100000, 31)\n",
      "some tf-idf values\n",
      "[0.         0.         0.         0.42782282 0.43669317 0.7050588 ]\n",
      "\n",
      "after feature extraction:\n",
      "X shape (1187039, 6)\n",
      "y shape (1187039,)\n",
      "some X values\n",
      "[[0.         0.         0.         0.42782282 0.43669317 0.7050588 ]\n",
      " [0.         0.         0.42782282 0.43669317 0.7050588  0.3593867 ]\n",
      " [0.         0.42782282 0.43669317 0.7050588  0.3593867  0.        ]\n",
      " [0.42782282 0.43669317 0.7050588  0.3593867  0.         0.        ]\n",
      " [0.43669317 0.7050588  0.3593867  0.         0.         0.        ]]\n",
      "some y values\n",
      "[0 1 0 0 0]\n",
      "non zero elements (1 in label) in y 100779\n",
      "class frequency ratio 0.014149914198269813\n",
      "\n"
     ]
    }
   ],
   "source": [
    "should_use_tfidf = True\n",
    "should_use_hybrid = False\n",
    "\n",
    "X_tfidf, y_tfidf = tfidf_features(text_lines_split, loc_lines, k, word_to_tfidf)\n",
    "X_w2v, y_w2v = w2v_features(text_lines_split, loc_lines, k)\n",
    "X_hybrid = np.hstack((X_tfidf, X_w2v))\n",
    "\n",
    "if should_use_tfidf or should_use_hybrid:    \n",
    "    X, y = X_tfidf, y_tfidf\n",
    "\n",
    "if (not should_use_tfidf) or should_use_hybrid:\n",
    "    X, y = X_w2v, y_w2v\n",
    "\n",
    "if should_use_hybrid:\n",
    "    X = X_hybrid\n",
    "\n",
    "print_dataset(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Build data sets\n",
    "Dataset is randomly split into train and test subsets. Ignored while using KFold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if not should_use_kfold:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_train[30:50])\n",
    "    print(y_train[30:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Baselines\n",
    "\n",
    "Make sure to check should_train flags when training/testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "should_use_kfold = True\n",
    "\n",
    "should_train_global = True\n",
    "should_train_linear_svm = True\n",
    "should_train_bagging_svm = False\n",
    "should_train_random_forest = True\n",
    "should_train_adaboost = False\n",
    "\n",
    "linear_svm_model_file_name = \"linear_svm.pkl\"\n",
    "bagging_model_file_name = \"bagging_svm.pkl\"\n",
    "random_forest_file_name = \"random_forest.pkl\"\n",
    "adaboost_file_name = \"adaboost.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "def calc_scores(y_pred, y_test):\n",
    "    result = []\n",
    "    result.append(accuracy_score(y_pred, y_test))\n",
    "    result.append(precision_score(y_pred, y_test))\n",
    "    result.append(recall_score(y_pred, y_test))\n",
    "    result.append(f1_score(y_pred, y_test))\n",
    "    result.append(np.count_nonzero(y_pred) / y_pred.shape[0])\n",
    "    return result\n",
    "\n",
    "def print_scores(scores):\n",
    "    print(f\"Accuracy: {scores[0]}\")\n",
    "    print(f\"Precision: {scores[1]}\")\n",
    "    print(f\"Recall: {scores[2]}\")\n",
    "    print(f\"F1: {scores[3]}\")\n",
    "    print(f\"ratio of positive/negative predictions {scores[4]}\")\n",
    "\n",
    "def kfold_score(clf, X, y):\n",
    "    fold_scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_kf, X_test_kf = X[train_index], X[test_index]\n",
    "        y_train_kf, y_test_kf = y[train_index], y[test_index]\n",
    "        clf.fit(X_train_kf, y_train_kf)\n",
    "        y_pred = clf.predict(X_test_kf)\n",
    "        fold_scores.append(calc_scores(y_pred, y_test_kf))\n",
    "    \n",
    "    fold_scores = np.average(np.asarray(fold_scores), axis=0)\n",
    "    print_scores(fold_scores)\n",
    "\n",
    "def train_and_save_model(model, X_train, y_train, model_file_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    joblib.dump(model, model_file_name)\n",
    "    \n",
    "def load_and_test_model(model_file_name, X_test, y_test):\n",
    "    clf_loaded = joblib.load(model_file_name)\n",
    "    y_pred = clf_loaded.predict(X_test)\n",
    "    print_scores(calc_scores(y_pred, y_test))\n",
    "    \n",
    "def do_test(clf, X, y, clf_file_name, flag):\n",
    "    if should_use_kfold:\n",
    "        kfold_score(clf, X, y)\n",
    "    else:\n",
    "        if should_train_global and flag:\n",
    "            train_and_save_model(clf, X_train, y_train, clf_file_name)\n",
    "        load_and_test_model(clf_file_name, X_test, y_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Linear SVM Baseline\n",
    "\n",
    "Linear SVM is based on the liblinear library and is faster on large datasets. Not using dual optimization problem makes the training extremely fast (pseudoinverse). It is the fastest so both feature extraction methods (TF-IDF and word2vec) are used for comparison. TF-IDF works better, but adding word2vec to it (hybrid approach) adds a little bit of improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF results:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ef0ff612fec7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TF-IDF results:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdo_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinear_svm_model_file_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshould_train_linear_svm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nword2vec results:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdo_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_w2v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_w2v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinear_svm_model_file_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshould_train_linear_svm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_clf = LinearSVC(class_weight=\"balanced\", dual=False)\n",
    "\n",
    "print(\"TF-IDF results:\")\n",
    "do_test(svm_clf, X_tfidf, y_tfidf, linear_svm_model_file_name, should_train_linear_svm)\n",
    "print(\"\\nword2vec results:\")\n",
    "do_test(svm_clf, X_w2v, y_w2v, linear_svm_model_file_name, should_train_linear_svm)\n",
    "print(\"\\nhybrid results:\")\n",
    "do_test(svm_clf, X_hybrid, y_w2v, linear_svm_model_file_name, should_train_linear_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Bagging SVM\n",
    "\n",
    "Warning! SVM is based on the libsvm library and it scales poorly with large datasets. That is why an ensemble (bagging) is used. Each classifier is trained on a portion of the data which greatly reduces training times and gives similar (if not better) results. Using 10 estimators it still takes a few hours to train. Results are just a bit better than a single linear SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "n_estimators = 10\n",
    "bagging_svm_clf = BaggingClassifier(SVC(kernel='linear', class_weight='balanced'), max_samples=1.0 / n_estimators,\n",
    "                                        n_estimators=n_estimators, bootstrap=False)\n",
    "\n",
    "do_test(bagging_svm_clf, X, y, bagging_model_file_name, should_train_bagging_svm)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Random Forest Baseline\n",
    "\n",
    "Random forests are pretty fast and are generally better than the SVM. Higher accuracy and recall, but worse precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9002408523237806\n",
      "Precision: 0.21676942055870857\n",
      "Recall: 0.3562221258643744\n",
      "F1: 0.26951362532394985\n",
      "ratio of positive/negative predictions 0.05166721459371121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest_clf = RandomForestClassifier(min_samples_leaf=2, class_weight=\"balanced\")\n",
    "\n",
    "do_test(random_forest_clf, X, y, random_forest_file_name, should_train_random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### AdaBoost Baseline\n",
    "\n",
    "AdaBoost gives the best results and is relatively fast to train. It is slower than random forests, but still faster than bagging svms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7394929726436992\n",
      "Precision: 0.6803645745677411\n",
      "Recall: 0.1984073000807087\n",
      "F1: 0.30721909881604825\n",
      "ratio of positive/negative predictions 0.2911336536033801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "adaboost_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2, class_weight=\"balanced\"), n_estimators=100)\n",
    "\n",
    "do_test(adaboost_clf, X, y, adaboost_file_name, should_train_adaboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLSTM for emoji location prediction\n",
    "\n",
    "Bidirectional long short-term memory recurrent network implementation using the Keras framework. Emoji location prediction is treated as a binary classification problem. INPUT_SIZE determines how much of the tweets are used for training. The model uses an embedding layer and its size is a hyperparameter. A single bidirectional layer is used which actually consists of two LSTM layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "TWEET_NUM = len(text_lines)\n",
    "# TWEET_NUM = 125000\n",
    "NUM_OF_VOCAB = 10000\n",
    "N_TIMESTEPS = MAX_WORDS_PER_TWEET\n",
    "N_CLASSES = 2\n",
    "TEST_SPLIT_SIZE = 0.25\n",
    "INPUT_SIZE = len(text_lines) * (1 - TEST_SPLIT_SIZE)\n",
    "EMBEDDING_SIZE = 101\n",
    "HIDDEN_SIZE = 52\n",
    "PARAMETER_STR = str(N_CLASSES) + \"_\" + str(INPUT_SIZE) + \"_\" + str(EMBEDDING_SIZE) + \"_\" + str(HIDDEN_SIZE)\n",
    "\n",
    "dummy_text = [\"\"\" Jack and Jill went up the hill\\n\n",
    "        To fetch a pail of water\\n\n",
    "        Jack fell down and broke his crown\\n\n",
    "        And Jill came tumbling after\\n \"\"\"]\n",
    "\n",
    "BLSTM_MODEL_FILE_NAME = \"blstm_model_\" + PARAMETER_STR + \".h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "Words are converted to integer ids using a tokenizer. Each unique word has its own unique integer value. Tweets are padded with zeros to a set length. Padding is required by Keras. Since most of the labels are zero (emojis are present after every 15th word), class weights are calculated. Without class weights the model behaves like a majority class classifier which is of no use here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded:\n",
      "[[3468, 37, 259, 347, 89, 659, 7, 6, 649, 259], [13, 268, 909, 3893, 3, 1475, 3109, 7035, 3363, 974, 5291, 114], [162, 29, 7501, 506, 26, 6, 845, 55, 29, 14, 56, 318, 7501, 2], [40, 321, 4575, 3865, 248], [46, 46, 643, 7, 229, 46]]\n",
      "\n",
      "Vocabulary Size: 10000\n",
      "input shape: (75000, 30)\n",
      "BLSTM input example:\n",
      "[[3468   37  259  347   89  659    7    6  649  259    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [  13  268  909 3893    3 1475 3109 7035 3363  974 5291  114    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [ 162   29 7501  506   26    6  845   55   29   14   56  318 7501    2\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [  40  321 4575 3865  248    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [  46   46  643    7  229   46    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "\n",
      "labels shape: (75000, 30, 2)\n",
      "class weight dict:\n",
      "{0: 0.5173783953819494, 1: 14.885677993013655}\n",
      "\n",
      "sample_weights shape: (75000, 30)\n",
      "sample_weights examples:\n",
      "[[ 0.5173784   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784\n",
      "   0.5173784   0.5173784   0.5173784   0.5173784  14.88567799  0.5173784\n",
      "   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784\n",
      "   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784\n",
      "   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784 ]\n",
      " [ 0.5173784   0.5173784   0.5173784   0.5173784   0.5173784  14.88567799\n",
      "   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784\n",
      "   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784\n",
      "   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784\n",
      "   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784 ]\n",
      " [ 0.5173784   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784\n",
      "   0.5173784   0.5173784  14.88567799  0.5173784   0.5173784   0.5173784\n",
      "   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784\n",
      "   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784\n",
      "   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784 ]\n",
      " [ 0.5173784  14.88567799  0.5173784   0.5173784   0.5173784   0.5173784\n",
      "   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784\n",
      "   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784\n",
      "   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784\n",
      "   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784 ]\n",
      " [14.88567799  0.5173784   0.5173784   0.5173784   0.5173784   0.5173784\n",
      "   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784\n",
      "   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784\n",
      "   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784\n",
      "   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784   0.5173784 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_input = text_lines[:TWEET_NUM]\n",
    "y_input = loc_lines[:TWEET_NUM]\n",
    "\n",
    "X_blstm_train, X_blstm_test, y_blstm_train, y_blstm_test = train_test_split(X_input, y_input, test_size=TEST_SPLIT_SIZE)\n",
    "\n",
    "# integer encode text\n",
    "tokenizer = Tokenizer(num_words=NUM_OF_VOCAB)\n",
    "tokenizer.fit_on_texts(X_input)\n",
    "txt_to_seq = tokenizer.texts_to_sequences(X_blstm_train)\n",
    "print(f\"encoded:\\n{txt_to_seq[0:5]}\\n\")\n",
    "# determine the vocabulary size\n",
    "\n",
    "vocab_size = NUM_OF_VOCAB\n",
    "# vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f\"Vocabulary Size: {vocab_size}\")\n",
    "\n",
    "# pad input sequences\n",
    "X_blstm = pad_sequences(txt_to_seq, maxlen=N_TIMESTEPS, padding='post')\n",
    "print(f\"input shape: {X_blstm.shape}\")\n",
    "print(f\"BLSTM input example:\\n{X_blstm[:5]}\\n\")\n",
    "\n",
    "y_loc = y_blstm_train[:,1:]\n",
    "y_blstm = to_categorical(y_loc, num_classes=N_CLASSES)\n",
    "print(f\"labels shape: {y_blstm.shape}\")\n",
    "# print(f\"BLSTM labels:\\n{y_blstm[:5]}\\n\")\n",
    "\n",
    "weights = class_weight.compute_class_weight('balanced', np.unique(y_loc), y_loc.flatten())\n",
    "class_weight_dict = dict(enumerate(weights))\n",
    "print(f\"class weight dict:\\n{class_weight_dict}\\n\")\n",
    "\n",
    "vfunc = np.vectorize(lambda x: class_weight_dict[x])\n",
    "sample_weights = vfunc(y_loc)\n",
    "print(f\"sample_weights shape: {sample_weights.shape}\")\n",
    "print(f\"sample_weights examples:\\n{sample_weights[:5]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Train model\n",
    " \n",
    " The following code is used to create and train a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "def get_blstm_file_name(embedding_size, hidden_size):\n",
    "    param_str = str(N_CLASSES) + \"_\" + str(INPUT_SIZE) + \"_\" + str(embedding_size) + \"_\" + str(hidden_size)\n",
    "    return \"blstm_model_\" + param_str + \".h5\"\n",
    "\n",
    "def save_blstm(blstm, embedding_size, hidden_size):\n",
    "    blstm.save(get_blstm_file_name(embedding_size, hidden_size))\n",
    "\n",
    "def load_blstm(embedding_size, hidden_size):\n",
    "    return load_model(get_blstm_file_name(embedding_size, hidden_size))\n",
    "\n",
    "hidden_sizes = [10, 30, 100]\n",
    "embedding_sizes = [2, 5, 10, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dropout\n",
    "\n",
    "should_train_blstm = False\n",
    "\n",
    "def get_bi_lstm_model(embedding_size=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE, n_timesteps=N_TIMESTEPS, mode=\"concat\"):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_size, input_length=N_TIMESTEPS))\n",
    "    model.add(Bidirectional(LSTM(hidden_size, return_sequences=True), merge_mode=mode))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(N_CLASSES, activation='softmax')))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"], sample_weight_mode=\"temporal\")\n",
    "    return model\n",
    "\n",
    "if should_train_blstm:\n",
    "    blstm = get_bi_lstm_model()\n",
    "    blstm.fit(X_blstm, y_blstm, epochs=20, validation_split=0.1, verbose=2, sample_weight=sample_weights)\n",
    "    save_blstm(blstm, EMBEDDING_SIZE, HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_blstm(blstm, EMBEDDING_SIZE, HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "embedding 2 hidden 10\n",
      "Train on 67500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      " - 173s - loss: 0.3872 - acc: 0.7206 - val_loss: 0.3450 - val_acc: 0.7746\n",
      "Epoch 2/10\n",
      " - 168s - loss: 0.3316 - acc: 0.7874 - val_loss: 0.3271 - val_acc: 0.7944\n",
      "Epoch 3/10\n",
      " - 168s - loss: 0.3038 - acc: 0.8170 - val_loss: 0.3084 - val_acc: 0.8361\n",
      "Epoch 4/10\n",
      " - 167s - loss: 0.2872 - acc: 0.8348 - val_loss: 0.3037 - val_acc: 0.8189\n",
      "Epoch 5/10\n",
      " - 168s - loss: 0.2792 - acc: 0.8416 - val_loss: 0.3055 - val_acc: 0.8354\n",
      "Epoch 6/10\n",
      " - 167s - loss: 0.2740 - acc: 0.8451 - val_loss: 0.3056 - val_acc: 0.8297\n",
      "Epoch 7/10\n",
      " - 168s - loss: 0.2703 - acc: 0.8469 - val_loss: 0.3144 - val_acc: 0.8540\n",
      "Epoch 8/10\n",
      " - 168s - loss: 0.2672 - acc: 0.8487 - val_loss: 0.3124 - val_acc: 0.8411\n",
      "Epoch 9/10\n",
      " - 167s - loss: 0.2648 - acc: 0.8498 - val_loss: 0.3185 - val_acc: 0.8560\n",
      "Epoch 10/10\n",
      " - 167s - loss: 0.2629 - acc: 0.8506 - val_loss: 0.3182 - val_acc: 0.8342\n",
      "\n",
      "embedding 5 hidden 10\n",
      "Train on 67500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      " - 170s - loss: 0.3423 - acc: 0.7842 - val_loss: 0.3061 - val_acc: 0.8163\n",
      "Epoch 2/10\n",
      " - 164s - loss: 0.2902 - acc: 0.8351 - val_loss: 0.3009 - val_acc: 0.8285\n",
      "Epoch 3/10\n",
      " - 164s - loss: 0.2737 - acc: 0.8470 - val_loss: 0.2992 - val_acc: 0.8477\n",
      "Epoch 4/10\n",
      " - 165s - loss: 0.2626 - acc: 0.8534 - val_loss: 0.3024 - val_acc: 0.8351\n",
      "Epoch 5/10\n",
      " - 164s - loss: 0.2542 - acc: 0.8577 - val_loss: 0.3130 - val_acc: 0.8506\n",
      "Epoch 6/10\n",
      " - 165s - loss: 0.2473 - acc: 0.8612 - val_loss: 0.3261 - val_acc: 0.8614\n",
      "Epoch 7/10\n",
      " - 165s - loss: 0.2415 - acc: 0.8637 - val_loss: 0.3331 - val_acc: 0.8548\n",
      "Epoch 8/10\n",
      " - 165s - loss: 0.2358 - acc: 0.8663 - val_loss: 0.3418 - val_acc: 0.8538\n",
      "Epoch 9/10\n",
      " - 165s - loss: 0.2308 - acc: 0.8683 - val_loss: 0.3636 - val_acc: 0.8614\n",
      "Epoch 10/10\n",
      " - 165s - loss: 0.2261 - acc: 0.8705 - val_loss: 0.3844 - val_acc: 0.8580\n",
      "\n",
      "embedding 10 hidden 10\n",
      "Train on 67500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      " - 171s - loss: 0.3356 - acc: 0.7930 - val_loss: 0.3023 - val_acc: 0.8237\n",
      "Epoch 2/10\n",
      " - 165s - loss: 0.2847 - acc: 0.8391 - val_loss: 0.2947 - val_acc: 0.8337\n",
      "Epoch 3/10\n",
      " - 165s - loss: 0.2665 - acc: 0.8509 - val_loss: 0.2972 - val_acc: 0.8483\n",
      "Epoch 4/10\n",
      " - 165s - loss: 0.2534 - acc: 0.8580 - val_loss: 0.3067 - val_acc: 0.8559\n",
      "Epoch 5/10\n",
      " - 166s - loss: 0.2426 - acc: 0.8631 - val_loss: 0.3240 - val_acc: 0.8657\n",
      "Epoch 6/10\n",
      " - 166s - loss: 0.2332 - acc: 0.8675 - val_loss: 0.3271 - val_acc: 0.8403\n",
      "Epoch 7/10\n",
      " - 166s - loss: 0.2249 - acc: 0.8712 - val_loss: 0.3670 - val_acc: 0.8726\n",
      "Epoch 8/10\n",
      " - 165s - loss: 0.2171 - acc: 0.8751 - val_loss: 0.3777 - val_acc: 0.8700\n",
      "Epoch 9/10\n",
      " - 165s - loss: 0.2106 - acc: 0.8787 - val_loss: 0.3986 - val_acc: 0.8651\n",
      "Epoch 10/10\n",
      " - 166s - loss: 0.2043 - acc: 0.8820 - val_loss: 0.4264 - val_acc: 0.8679\n",
      "\n",
      "embedding 15 hidden 10\n",
      "Train on 67500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      " - 172s - loss: 0.3312 - acc: 0.7966 - val_loss: 0.2996 - val_acc: 0.8308\n",
      "Epoch 2/10\n",
      " - 167s - loss: 0.2813 - acc: 0.8406 - val_loss: 0.2934 - val_acc: 0.8326\n",
      "Epoch 3/10\n",
      " - 166s - loss: 0.2629 - acc: 0.8526 - val_loss: 0.2971 - val_acc: 0.8434\n",
      "Epoch 4/10\n",
      " - 167s - loss: 0.2492 - acc: 0.8598 - val_loss: 0.3077 - val_acc: 0.8493\n",
      "Epoch 5/10\n",
      " - 167s - loss: 0.2372 - acc: 0.8655 - val_loss: 0.3205 - val_acc: 0.8546\n",
      "Epoch 6/10\n",
      " - 167s - loss: 0.2266 - acc: 0.8710 - val_loss: 0.3333 - val_acc: 0.8541\n",
      "Epoch 7/10\n",
      " - 167s - loss: 0.2168 - acc: 0.8765 - val_loss: 0.3683 - val_acc: 0.8695\n",
      "Epoch 8/10\n",
      " - 167s - loss: 0.2079 - acc: 0.8813 - val_loss: 0.3750 - val_acc: 0.8576\n",
      "Epoch 9/10\n",
      " - 167s - loss: 0.1998 - acc: 0.8862 - val_loss: 0.4007 - val_acc: 0.8637\n",
      "Epoch 10/10\n",
      " - 167s - loss: 0.1923 - acc: 0.8907 - val_loss: 0.4454 - val_acc: 0.8729\n",
      "\n",
      "embedding 2 hidden 30\n",
      "Train on 67500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      " - 174s - loss: 0.3580 - acc: 0.7556 - val_loss: 0.3219 - val_acc: 0.7991\n",
      "Epoch 2/10\n",
      " - 168s - loss: 0.2994 - acc: 0.8243 - val_loss: 0.2977 - val_acc: 0.8338\n",
      "Epoch 3/10\n",
      " - 168s - loss: 0.2828 - acc: 0.8399 - val_loss: 0.2947 - val_acc: 0.8389\n",
      "Epoch 4/10\n",
      " - 168s - loss: 0.2741 - acc: 0.8457 - val_loss: 0.3037 - val_acc: 0.8520\n",
      "Epoch 5/10\n",
      " - 168s - loss: 0.2683 - acc: 0.8485 - val_loss: 0.3071 - val_acc: 0.8546\n",
      "Epoch 6/10\n",
      " - 167s - loss: 0.2644 - acc: 0.8506 - val_loss: 0.3077 - val_acc: 0.8495\n",
      "Epoch 7/10\n",
      " - 167s - loss: 0.2612 - acc: 0.8516 - val_loss: 0.3088 - val_acc: 0.8524\n",
      "Epoch 8/10\n",
      " - 167s - loss: 0.2584 - acc: 0.8528 - val_loss: 0.3156 - val_acc: 0.8553\n",
      "Epoch 9/10\n",
      " - 167s - loss: 0.2561 - acc: 0.8535 - val_loss: 0.3192 - val_acc: 0.8537\n",
      "Epoch 10/10\n",
      " - 167s - loss: 0.2541 - acc: 0.8547 - val_loss: 0.3217 - val_acc: 0.8438\n",
      "\n",
      "embedding 5 hidden 30\n",
      "Train on 67500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      " - 173s - loss: 0.3411 - acc: 0.7793 - val_loss: 0.3016 - val_acc: 0.8021\n",
      "Epoch 2/10\n",
      " - 166s - loss: 0.2853 - acc: 0.8363 - val_loss: 0.2944 - val_acc: 0.8204\n",
      "Epoch 3/10\n",
      " - 165s - loss: 0.2680 - acc: 0.8480 - val_loss: 0.2950 - val_acc: 0.8414\n",
      "Epoch 4/10\n",
      " - 166s - loss: 0.2555 - acc: 0.8552 - val_loss: 0.3030 - val_acc: 0.8503\n",
      "Epoch 5/10\n",
      " - 165s - loss: 0.2452 - acc: 0.8602 - val_loss: 0.3090 - val_acc: 0.8401\n",
      "Epoch 6/10\n",
      " - 165s - loss: 0.2362 - acc: 0.8645 - val_loss: 0.3309 - val_acc: 0.8537\n",
      "Epoch 7/10\n",
      " - 165s - loss: 0.2283 - acc: 0.8683 - val_loss: 0.3397 - val_acc: 0.8497\n",
      "Epoch 8/10\n",
      " - 165s - loss: 0.2217 - acc: 0.8713 - val_loss: 0.3647 - val_acc: 0.8587\n",
      "Epoch 9/10\n",
      " - 165s - loss: 0.2160 - acc: 0.8740 - val_loss: 0.4167 - val_acc: 0.8733\n",
      "Epoch 10/10\n",
      " - 165s - loss: 0.2112 - acc: 0.8762 - val_loss: 0.4067 - val_acc: 0.8560\n",
      "\n",
      "embedding 10 hidden 30\n",
      "Train on 67500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      " - 173s - loss: 0.3276 - acc: 0.7983 - val_loss: 0.2963 - val_acc: 0.8202\n",
      "Epoch 2/10\n",
      " - 167s - loss: 0.2803 - acc: 0.8413 - val_loss: 0.2930 - val_acc: 0.8491\n",
      "Epoch 3/10\n",
      " - 167s - loss: 0.2631 - acc: 0.8521 - val_loss: 0.2933 - val_acc: 0.8430\n",
      "Epoch 4/10\n",
      " - 167s - loss: 0.2493 - acc: 0.8596 - val_loss: 0.3039 - val_acc: 0.8528\n",
      "Epoch 5/10\n",
      " - 167s - loss: 0.2374 - acc: 0.8655 - val_loss: 0.3183 - val_acc: 0.8485\n",
      "Epoch 6/10\n",
      " - 167s - loss: 0.2267 - acc: 0.8710 - val_loss: 0.3398 - val_acc: 0.8660\n",
      "Epoch 7/10\n",
      " - 166s - loss: 0.2170 - acc: 0.8763 - val_loss: 0.3769 - val_acc: 0.8746\n",
      "Epoch 8/10\n",
      " - 167s - loss: 0.2079 - acc: 0.8812 - val_loss: 0.3769 - val_acc: 0.8526\n",
      "Epoch 9/10\n",
      " - 166s - loss: 0.1991 - acc: 0.8858 - val_loss: 0.4272 - val_acc: 0.8700\n",
      "Epoch 10/10\n",
      " - 167s - loss: 0.1911 - acc: 0.8900 - val_loss: 0.4543 - val_acc: 0.8662\n",
      "\n",
      "embedding 15 hidden 30\n",
      "Train on 67500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      " - 172s - loss: 0.3242 - acc: 0.8010 - val_loss: 0.2960 - val_acc: 0.8250\n",
      "Epoch 2/10\n",
      " - 166s - loss: 0.2762 - acc: 0.8439 - val_loss: 0.2926 - val_acc: 0.8418\n",
      "Epoch 3/10\n",
      " - 166s - loss: 0.2573 - acc: 0.8550 - val_loss: 0.2967 - val_acc: 0.8471\n",
      "Epoch 4/10\n",
      " - 166s - loss: 0.2424 - acc: 0.8631 - val_loss: 0.3065 - val_acc: 0.8525\n",
      "Epoch 5/10\n",
      " - 166s - loss: 0.2294 - acc: 0.8693 - val_loss: 0.3240 - val_acc: 0.8539\n",
      "Epoch 6/10\n",
      " - 166s - loss: 0.2174 - acc: 0.8762 - val_loss: 0.3614 - val_acc: 0.8693\n",
      "Epoch 7/10\n",
      " - 166s - loss: 0.2068 - acc: 0.8822 - val_loss: 0.3813 - val_acc: 0.8665\n",
      "Epoch 8/10\n",
      " - 166s - loss: 0.1963 - acc: 0.8884 - val_loss: 0.4400 - val_acc: 0.8818\n",
      "Epoch 9/10\n",
      " - 165s - loss: 0.1865 - acc: 0.8941 - val_loss: 0.4732 - val_acc: 0.8793\n",
      "Epoch 10/10\n",
      " - 165s - loss: 0.1786 - acc: 0.8988 - val_loss: 0.5241 - val_acc: 0.8835\n",
      "\n",
      "embedding 2 hidden 100\n",
      "Train on 67500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      " - 174s - loss: 0.3538 - acc: 0.7581 - val_loss: 0.3103 - val_acc: 0.8044\n",
      "Epoch 2/10\n",
      " - 168s - loss: 0.2942 - acc: 0.8296 - val_loss: 0.2946 - val_acc: 0.8244\n",
      "Epoch 3/10\n",
      " - 168s - loss: 0.2785 - acc: 0.8408 - val_loss: 0.2974 - val_acc: 0.8535\n",
      "Epoch 4/10\n",
      " - 168s - loss: 0.2709 - acc: 0.8453 - val_loss: 0.2997 - val_acc: 0.8468\n",
      "Epoch 5/10\n",
      " - 167s - loss: 0.2652 - acc: 0.8482 - val_loss: 0.3005 - val_acc: 0.8413\n",
      "Epoch 6/10\n",
      " - 167s - loss: 0.2609 - acc: 0.8502 - val_loss: 0.3050 - val_acc: 0.8415\n",
      "Epoch 7/10\n",
      " - 168s - loss: 0.2576 - acc: 0.8517 - val_loss: 0.3131 - val_acc: 0.8497\n",
      "Epoch 8/10\n",
      " - 167s - loss: 0.2549 - acc: 0.8532 - val_loss: 0.3162 - val_acc: 0.8502\n",
      "Epoch 9/10\n",
      " - 167s - loss: 0.2524 - acc: 0.8543 - val_loss: 0.3209 - val_acc: 0.8501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      " - 167s - loss: 0.2501 - acc: 0.8554 - val_loss: 0.3291 - val_acc: 0.8459\n",
      "\n",
      "embedding 5 hidden 100\n",
      "Train on 67500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      " - 173s - loss: 0.3304 - acc: 0.7891 - val_loss: 0.2962 - val_acc: 0.8231\n",
      "Epoch 2/10\n",
      " - 166s - loss: 0.2832 - acc: 0.8374 - val_loss: 0.2924 - val_acc: 0.8377\n",
      "Epoch 3/10\n",
      " - 166s - loss: 0.2681 - acc: 0.8480 - val_loss: 0.2915 - val_acc: 0.8375\n",
      "Epoch 4/10\n",
      " - 167s - loss: 0.2565 - acc: 0.8548 - val_loss: 0.3094 - val_acc: 0.8593\n",
      "Epoch 5/10\n",
      " - 167s - loss: 0.2465 - acc: 0.8598 - val_loss: 0.3075 - val_acc: 0.8446\n",
      "Epoch 6/10\n",
      " - 167s - loss: 0.2370 - acc: 0.8643 - val_loss: 0.3292 - val_acc: 0.8591\n",
      "Epoch 7/10\n",
      " - 167s - loss: 0.2286 - acc: 0.8686 - val_loss: 0.3465 - val_acc: 0.8623\n",
      "Epoch 8/10\n",
      " - 167s - loss: 0.2210 - acc: 0.8720 - val_loss: 0.3789 - val_acc: 0.8711\n",
      "Epoch 9/10\n",
      " - 167s - loss: 0.2147 - acc: 0.8754 - val_loss: 0.3902 - val_acc: 0.8657\n",
      "Epoch 10/10\n",
      " - 167s - loss: 0.2090 - acc: 0.8781 - val_loss: 0.4130 - val_acc: 0.8723\n",
      "\n",
      "embedding 10 hidden 100\n",
      "Train on 67500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      " - 173s - loss: 0.3255 - acc: 0.7956 - val_loss: 0.2946 - val_acc: 0.8332\n",
      "Epoch 2/10\n",
      " - 167s - loss: 0.2780 - acc: 0.8417 - val_loss: 0.2895 - val_acc: 0.8282\n",
      "Epoch 3/10\n",
      " - 167s - loss: 0.2596 - acc: 0.8534 - val_loss: 0.2976 - val_acc: 0.8579\n",
      "Epoch 4/10\n",
      " - 167s - loss: 0.2448 - acc: 0.8614 - val_loss: 0.3004 - val_acc: 0.8464\n",
      "Epoch 5/10\n",
      " - 166s - loss: 0.2322 - acc: 0.8678 - val_loss: 0.3357 - val_acc: 0.8639\n",
      "Epoch 6/10\n",
      " - 166s - loss: 0.2200 - acc: 0.8745 - val_loss: 0.3477 - val_acc: 0.8617\n",
      "Epoch 7/10\n",
      " - 167s - loss: 0.2088 - acc: 0.8806 - val_loss: 0.3750 - val_acc: 0.8676\n",
      "Epoch 8/10\n",
      " - 166s - loss: 0.1990 - acc: 0.8861 - val_loss: 0.4193 - val_acc: 0.8720\n",
      "Epoch 9/10\n",
      " - 166s - loss: 0.1901 - acc: 0.8909 - val_loss: 0.4567 - val_acc: 0.8735\n",
      "Epoch 10/10\n",
      " - 166s - loss: 0.1813 - acc: 0.8961 - val_loss: 0.5176 - val_acc: 0.8786\n",
      "\n",
      "embedding 15 hidden 100\n",
      "Train on 67500 samples, validate on 7500 samples\n",
      "Epoch 1/10\n",
      " - 174s - loss: 0.3189 - acc: 0.8030 - val_loss: 0.2906 - val_acc: 0.8341\n",
      "Epoch 2/10\n",
      " - 167s - loss: 0.2750 - acc: 0.8436 - val_loss: 0.2898 - val_acc: 0.8449\n",
      "Epoch 3/10\n",
      " - 167s - loss: 0.2562 - acc: 0.8550 - val_loss: 0.2916 - val_acc: 0.8420\n",
      "Epoch 4/10\n",
      " - 167s - loss: 0.2407 - acc: 0.8635 - val_loss: 0.3056 - val_acc: 0.8560\n",
      "Epoch 5/10\n",
      " - 168s - loss: 0.2260 - acc: 0.8716 - val_loss: 0.3283 - val_acc: 0.8651\n",
      "Epoch 6/10\n",
      " - 167s - loss: 0.2103 - acc: 0.8803 - val_loss: 0.3802 - val_acc: 0.8721\n",
      "Epoch 7/10\n",
      " - 167s - loss: 0.1954 - acc: 0.8889 - val_loss: 0.3964 - val_acc: 0.8707\n",
      "Epoch 8/10\n",
      " - 167s - loss: 0.1826 - acc: 0.8965 - val_loss: 0.4767 - val_acc: 0.8869\n",
      "Epoch 9/10\n",
      " - 167s - loss: 0.1713 - acc: 0.9034 - val_loss: 0.5633 - val_acc: 0.8870\n",
      "Epoch 10/10\n",
      " - 167s - loss: 0.1613 - acc: 0.9097 - val_loss: 0.6143 - val_acc: 0.8884\n"
     ]
    }
   ],
   "source": [
    "for hidden_size in hidden_sizes:\n",
    "    for embedding_size in embedding_sizes:\n",
    "        blstm = get_bi_lstm_model(embedding_size=embedding_size, hidden_size=hidden_size)\n",
    "        print(f\"\\nembedding {embedding_size} hidden {hidden_size}\")\n",
    "        blstm.fit(X_blstm, y_blstm, epochs=10, validation_split=0.1, verbose=2, sample_weight=sample_weights)\n",
    "        save_blstm(blstm, embedding_size, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a model\n",
    "\n",
    "The following block is used to load models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "blstm = load_model(BLSTM_MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example of labels (emoji locations):\n",
      "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "model predictions:\n",
      "[[0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_OF_TWEETS_TO_TEST = 10\n",
    "\n",
    "def get_predictions(blstm, texts):\n",
    "    text_to_integer_sequences = tokenizer.texts_to_sequences(texts)\n",
    "    blstm_input = pad_sequences(text_to_integer_sequences, maxlen=N_TIMESTEPS, padding='post')\n",
    "    ypred = blstm.predict_classes(blstm_input)\n",
    "    return np.insert(ypred, 0, 0, axis=1)\n",
    "\n",
    "print(f\"example of labels (emoji locations):\\n{y_input[:NUM_OF_TWEETS_TO_TEST]}\\n\")\n",
    "print(f\"model predictions:\\n{get_predictions(blstm, X_input[:NUM_OF_TWEETS_TO_TEST])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load/Save predictions\n",
    "\n",
    "Use the code below to save/load a model's predictions. Training and testing the model requires a powerful Nvidia GPU and is time consuming. This also enables the evaluation of results without having to work with the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blstm_predictions_flag = False\n",
    "\n",
    "if blstm_predictions_flag:\n",
    "    BLSTM_PREDICTIONS_FILE_NAME = \"blstm_predictions_\" + PARAMETER_STR + \".pkl\"\n",
    "    predictions = get_predictions(text_lines)\n",
    "\n",
    "    result_dict = {}\n",
    "    result_dict[\"num_of_classes\"] = N_CLASSES\n",
    "    result_dict[\"num_of_input_tweets\"] = INPUT_SIZE\n",
    "    result_dict[\"embedding_size\"] = EMBEDDING_SIZE\n",
    "    result_dict[\"hidden_size\"] = HIDDEN_SIZE\n",
    "    result_dict[\"input_X\"] = X_blstm\n",
    "    result_dict[\"input_y\"] = y_blstm\n",
    "    result_dict[\"ypred\"] = predictions\n",
    "\n",
    "    joblib.dump(result_dict, BLSTM_PREDICTIONS_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if blstm_predictions_flag:\n",
    "    result_dict = joblib.load(BLSTM_PREDICTIONS_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_blstm(blstm, texts, labels):\n",
    "    predictions = get_predictions(blstm, texts)\n",
    "    print_scores(calc_scores(predictions.flatten(), labels.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:\n",
      "Accuracy: 0.8842885074631341\n",
      "Precision: 0.6137139825591034\n",
      "Recall: 0.16381856843512066\n",
      "F1: 0.25860716936645856\n",
      "ratio of positive/negative predictions 0.12319002745709369\n",
      "\n",
      "train:\n",
      "Accuracy: 0.929224556024226\n",
      "Precision: 0.8889981466085145\n",
      "Recall: 0.30345990224475017\n",
      "F1: 0.4524692351651533\n",
      "ratio of positive/negative predictions 0.09636777284635417\n"
     ]
    }
   ],
   "source": [
    "print(f\"test:\")\n",
    "evaluate_blstm(blstm, X_blstm_test, y_blstm_test)\n",
    "print(f\"\\ntrain:\")\n",
    "evaluate_blstm(blstm, X_blstm_train, y_blstm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8684525806451613\n",
      "Precision: 0.8862431529333372\n",
      "Recall: 0.18585372870558742\n",
      "F1: 0.3072699815349909\n",
      "ratio of positive/negative predictions 0.15697741935483872\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding 2 hidden 10\n",
      "Accuracy: 0.8404877419354839\n",
      "Precision: 0.8914559721011334\n",
      "Recall: 0.15689296823780496\n",
      "F1: 0.2668256114630038\n",
      "ratio of positive/negative predictions 0.18500387096774193\n",
      "\n",
      "Embedding 5 hidden 10\n",
      "Accuracy: 0.8631083870967742\n",
      "Precision: 0.8475073313782991\n",
      "Recall: 0.1729853028011227\n",
      "F1: 0.2873245870364026\n",
      "ratio of positive/negative predictions 0.15952129032258064\n",
      "\n",
      "Embedding 10 hidden 10\n",
      "Accuracy: 0.8726167741935484\n",
      "Precision: 0.8230958230958231\n",
      "Recall: 0.1805647320652363\n",
      "F1: 0.2961600433474498\n",
      "ratio of positive/negative predictions 0.14842322580645162\n",
      "\n",
      "Embedding 15 hidden 10\n",
      "Accuracy: 0.8778064516129033\n",
      "Precision: 0.8175081239597368\n",
      "Recall: 0.18631010440374263\n",
      "F1: 0.30346136306800625\n",
      "ratio of positive/negative predictions 0.14286967741935483\n",
      "\n",
      "Embedding 2 hidden 30\n"
     ]
    }
   ],
   "source": [
    "for hidden_size in hidden_sizes:\n",
    "    for embedding_size in embedding_sizes:\n",
    "        blstm = load_blstm(embedding_size, hidden_size)\n",
    "        print(f\"\\nEmbedding {embedding_size} hidden {hidden_size}\")\n",
    "        evaluate_blstm(blstm, X_blstm_test, y_blstm_test)"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
